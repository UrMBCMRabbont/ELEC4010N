{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jLPJjp76lZMY",
        "ASCCtcZzsZbv",
        "lQt5adIhPPIt",
        "O38A5I8dBnrA"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: https://drive.google.com/u/0/uc?id=1p33nsWQaiZMAgsruDoJLyatoq5XAH-TH&export=download\n",
        "\n",
        "Baseline code: https://github.com/emma-sjwang/Dofe"
      ],
      "metadata": {
        "id": "z7rWTqmmi34W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm Implementation\n",
        "\n",
        "1. Implement the naive baseline model for comparison. This is typically a simple model with basic feature extraction and classification steps.\n",
        "\n",
        "2. Choose at least one Domain Generalization (DG) method to implement and compare against the naive baseline. This could be FACT, Dofe, or another method of your choice.\n",
        "\n",
        "3. Report the segmentation performance in terms of dice coefficient and average surface distance."
      ],
      "metadata": {
        "id": "ikoXfMF_lOJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd \"/content/gdrive/MyDrive/Colab Notebooks/ELEC4010N/Final Project/Project2\"\n",
        "!unzip \"/content/gdrive/MyDrive/Colab Notebooks/ELEC4010N/Final Project/Project2/Fundus-doFE.zip\" -d \"/content/\"\n",
        "\n",
        "# pip install external lib\n",
        "!pip install -U albumentations\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install torchmetrics\n",
        "!git clone https://github.com/deepmind/surface-distance.git\n",
        "!pip install surface-distance/"
      ],
      "metadata": {
        "id": "IBA8GHAbJ-Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset info\n",
        "[cup]Domian1: Drishti-GS dataset [101] including training[50] and testing[51]\n",
        "\n",
        "[cup]Domain2: RIM-ONE_r3 dataset [159] including training and[99] testing[60]. \n",
        "\n",
        "[cup]Domain3: REFUGE training [400]  MICCAI 2018 workshop including training and[320] testing[80]. \n",
        "\n",
        "[cup]Domian4: REFUGE val [400]  including training and[320] testing[80]. \n",
        "Domain5: ISBI [81]  IDRID chanllenge\n",
        "\n"
      ],
      "metadata": {
        "id": "KB_yBwBhTu45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 3 classes\n",
        "label = cv2.imread(\"/content/train/mask/G-1-L.png\", cv2.IMREAD_GRAYSCALE)\n",
        "np.unique(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlDSxZpb1uBo",
        "outputId": "c984aee3-f96f-43ac-8887-5197e27fa72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0, 128, 255], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Baseline Model"
      ],
      "metadata": {
        "id": "jLPJjp76lZMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just for reference\n",
        "# UNet implementation\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True))\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv_down1 = double_conv(3, 64)      # Number of channel\n",
        "        self.conv_down2 = double_conv(64, 128)\n",
        "        self.conv_down3 = double_conv(128, 256)\n",
        "        self.conv_down4 = double_conv(256, 512)        \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.conv_up3 = double_conv(256 + 512, 256)\n",
        "        self.conv_up2 = double_conv(128 + 256, 128)\n",
        "        self.conv_up1 = double_conv(128 + 64, 64)\n",
        "        \n",
        "        self.last_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "        # Weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "        conv2 = self.conv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        conv3 = self.conv_down3(x)\n",
        "        x = self.maxpool(conv3)\n",
        "        x = self.conv_down4(x)\n",
        "        x = self.upsample(x)\n",
        "        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.conv_up3(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.conv_up2(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        \n",
        "        x = self.conv_up1(x)\n",
        "        out = self.last_conv(x)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "2cHXXW2wj-Cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e76674d-421a-4e19-df57-1c778ba97383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6ff8d284c3c9>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         nn.ReLU(inplace=True))\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model = UNet(num_classes=1).to(device)\n",
        "output = model(torch.randn(1,3,256,256).to(device))\n",
        "print(f'Output shape: {output.shape}')"
      ],
      "metadata": {
        "id": "1LQxOa7tkAA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FACT\n",
        "\n",
        "https://github.com/MediaBrain-SJTU/FACT"
      ],
      "metadata": {
        "id": "gEwWV9bcle8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import math\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import random as randpy\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "\n",
        "# PyTorch imports for deep learning\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, ConcatDataset, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.models as models\n",
        "from torchvision.models import resnet50 as _resnet50\n",
        "from torchsummary import summary\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Other utilities\n",
        "import cv2\n",
        "from pylab import *\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "from google.colab.patches import cv2_imshow\n",
        "import albumentations as Augm\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from ast import In\n",
        "import surface_distance as surfdist\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchmetrics.classification import BinaryJaccardIndex"
      ],
      "metadata": {
        "id": "w_qdq2stHBS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmXdlqNFhHCN",
        "outputId": "6e3ab1f1-f74c-49d9-b14f-ca907ac10d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to move the data\n",
        "train_path = \"./train\"\n",
        "val_path = \"./val\"\n",
        "test_path = \"./test\"\n",
        "\n",
        "# Define the path to load the data\n",
        "D_mask_dir = [[\"./Fundus/Domain1/train/mask\", \"./Fundus/Domain1/test/mask\"],\n",
        "              [\"./Fundus/Domain2/train/mask\", \"./Fundus/Domain2/test/mask\"],\n",
        "              [\"./Fundus/Domain3/train/mask\", \"./Fundus/Domain3/test/mask\"],\n",
        "              [\"./Fundus/Domain4/train/mask\", \"./Fundus/Domain4/test/mask\"]]\n",
        "\n",
        "# Define the fundus dataset class to load the data by functions\n",
        "class FundusDataset(Dataset):\n",
        "    # Define the constructor\n",
        "    def __init__(self, path, transform, transform_mask, split_idx):\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        self.transform_mask = transform_mask\n",
        "        self.split_idx = split_idx\n",
        "        self.path_df = self.create_path_df()\n",
        "    \n",
        "    # Creates a DataFrame with image and mask paths\n",
        "    def create_path_df(self):\n",
        "        dirsImg, images, dirsMask, masks = [], [], [], []\n",
        "        \n",
        "        for mask_dir in self.path:\n",
        "            for img_path in mask_dir:\n",
        "                for _, _, files in os.walk(img_path):\n",
        "                    for file in files:\n",
        "                        check_mask = cv2.imread(os.path.join(img_path, file), cv2.IMREAD_GRAYSCALE)\n",
        "                        \n",
        "                        if check_mask.sum() > 0:\n",
        "                            domain = re.search(r'Domain\\d', img_path).group() # Extract domain\n",
        "                            match (domain):\n",
        "                                case 'Domain1':\n",
        "                                    images.append(file)\n",
        "                                case 'Domain2':\n",
        "                                    images.append(file.replace('png','jpg'))\n",
        "                                case 'Domain3':\n",
        "                                    images.append(file.replace('bmp','jpg'))\n",
        "                                case 'Domain4':\n",
        "                                    images.append(file.replace('bmp','jpg'))\n",
        "\n",
        "                            masks.append(file)\n",
        "                            dirsMask.append(img_path+'/')\n",
        "                            dirsImg.append(img_path.replace('mask','image')+'/')\n",
        "\n",
        "        return pd.DataFrame({'direcImg':dirsImg, 'images':images, 'direcMask':dirsMask, 'masks':masks})\n",
        "    \n",
        "    # Splits the train dataset into train and validation based on the split index\n",
        "    def split_traindataset(self):\n",
        "        for i in range(len(self.path_df)):\n",
        "            image_direc = self.path_df.loc[i]['direcImg'][:-1] + '/' + self.path_df.loc[i]['images']\n",
        "            mask_direc = self.path_df.loc[i]['direcMask'][:-1] + '/' + self.path_df.loc[i]['masks']\n",
        "            domain = re.search(r'Domain\\d', image_direc).group() if image_direc else None\n",
        "            \n",
        "            # Split the dataset based on the project description\n",
        "            if domain:\n",
        "                if domain != \"Domain4\":\n",
        "                    destination_path = train_path if i < int(0.8 * len(self.path_df)) else val_path\n",
        "                    shutil.copy(image_direc, destination_path + \"/image/\")\n",
        "                    shutil.copy(mask_direc, destination_path + \"/mask/\")\n",
        "                elif domain != \"Domain3\":\n",
        "                    destination_path = train_path if i < int(0.8 * len(self.path_df)) else val_path\n",
        "                    shutil.copy(image_direc, destination_path + \"/image/\")\n",
        "                    shutil.copy(mask_direc, destination_path + \"/mask/\")\n",
        "                elif domain != \"Domain2\":\n",
        "                    destination_path = train_path if i < int(0.8 * len(self.path_df)) else val_path\n",
        "                    shutil.copy(image_direc, destination_path + \"/image/\")\n",
        "                    shutil.copy(mask_direc, destination_path + \"/mask/\")\n",
        "                elif domain != \"Domain1\":\n",
        "                    destination_path = train_path if i < int(0.8 * len(self.path_df)) else val_path\n",
        "                    shutil.copy(image_direc, destination_path + \"/image/\")\n",
        "                    shutil.copy(mask_direc, destination_path + \"/mask/\")\n",
        "\n",
        "        return self.trainGetitem()\n",
        "\n",
        "    # Moves the test dataset to the test path\n",
        "    def split_testdataset(self):\n",
        "        for i in range(len(self.path_df)):\n",
        "            image_direc = self.path_df.loc[i]['direcImg'][:-1]+'/'+self.path_df.loc[i]['images']\n",
        "            mask_direc = self.path_df.loc[i]['direcMask'][:-1]+'/'+self.path_df.loc[i]['masks']\n",
        "            shutil.copy(image_direc, test_path+\"/image/\")\n",
        "            shutil.copy(mask_direc, test_path+\"/mask/\")\n",
        "\n",
        "        return self.testGetitem()\n",
        "\n",
        "    # Returns length of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.path_df)\n",
        "\n",
        "    # Processes the images and masks in the given directory\n",
        "    def process_images(self, directory, transform):\n",
        "        images = []\n",
        "        masks = []\n",
        "        folders = os.listdir(directory)\n",
        "        \n",
        "        for folder in folders:\n",
        "            files = os.listdir(os.path.join(directory, folder))\n",
        "            \n",
        "            for file in files:\n",
        "                direc = os.path.join(directory, folder, file)\n",
        "                \n",
        "                if 'mask' in folder:\n",
        "                    mask = cv2.imread(direc, cv2.IMREAD_GRAYSCALE)\n",
        "                    mask = transform(mask)\n",
        "                    mask = torch.round(mask)\n",
        "                    masks.append(mask)\n",
        "                else:\n",
        "                    fundus_img = cv2.imread(direc)\n",
        "                    fundus_img = transform(fundus_img)\n",
        "                    images.append(fundus_img)\n",
        "        \n",
        "        return images, masks\n",
        "\n",
        "    # Gets the train and validation items\n",
        "    def trainGetitem(self):\n",
        "        trainImg, trainMask = self.process_images(train_path, self.transform)\n",
        "        valImg, valMask = self.process_images(val_path, self.transform)\n",
        "        return [[trainImg, trainMask], [valImg, valMask]]\n",
        "\n",
        "    # Gets the test items\n",
        "    def testGetitem(self):\n",
        "        testImg, testMask = self.process_images(test_path, self.transform)\n",
        "        return [[testImg, testMask]]\n",
        "\n",
        "    #  Creates a list of image and mask paths\n",
        "    def direc(self):\n",
        "        FundusImg_direc = []\n",
        "        Mask_direc = []\n",
        "        train_folders = os.listdir(train_path)\n",
        "        \n",
        "        for folder in train_folders:\n",
        "            files = os.listdir(os.path.join(train_path, folder))\n",
        "            \n",
        "            for file in files:\n",
        "                direc = os.path.join(train_path, folder, file)\n",
        "                \n",
        "                if 'mask' in folder:\n",
        "                    Mask_direc.append(direc)\n",
        "                else:\n",
        "                    FundusImg_direc.append(direc)\n",
        "        \n",
        "        return FundusImg_direc, Mask_direc\n",
        "\n",
        "    # Stacks the datasets\n",
        "    def stack_datasets(self, datasets):\n",
        "        stacked_datasets = []\n",
        "        \n",
        "        for dataset in datasets:\n",
        "            fundus = dataset[0]\n",
        "            mask = dataset[1]\n",
        "            inputs = torch.stack(fundus)\n",
        "            labels = torch.stack(mask)\n",
        "            stacked_datasets.append(TensorDataset(inputs, labels))\n",
        "        \n",
        "        return stacked_datasets\n",
        "\n",
        "    # Stacks the train and validation datasets\n",
        "    def stack_train(self):\n",
        "        datasets = self.trainGetitem()\n",
        "        return self.stack_datasets(datasets)\n",
        "\n",
        "    # Stacks the test dataset\n",
        "    def stack_test(self):\n",
        "        datasets = self.testGetitem()\n",
        "        return self.stack_datasets(datasets)[0]"
      ],
      "metadata": {
        "id": "d9xTyMmkHiT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the train, validation, and test folders\n",
        "for path in [train_path, val_path, test_path]:\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n",
        "    os.makedirs(os.path.join(path, \"image\"))\n",
        "    os.makedirs(os.path.join(path, \"mask\"))\n",
        "\n",
        "# Normalization\n",
        "normalization = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(64),\n",
        "    transforms.RandomCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create the datasets\n",
        "# train = 1,2,3 test= 4\n",
        "train_class = FundusDataset(D_mask_dir[:3], transform=normalization, transform_mask=normalization, split_idx=1)\n",
        "test_class = FundusDataset(D_mask_dir[3:], transform=normalization, transform_mask=normalization, split_idx=1)\n",
        "\n",
        "# Split files of system\n",
        "train_class.split_traindataset()\n",
        "test_class.split_testdataset()"
      ],
      "metadata": {
        "id": "4p8xLZdGxAqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data_utils.py"
      ],
      "metadata": {
        "id": "ASCCtcZzsZbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/\""
      ],
      "metadata": {
        "id": "R-xsxxEzYJAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6365482d-584a-48dd-e30c-459a66518372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_info(filepath):\n",
        "    img_direcs = []\n",
        "    mask_direcs = []\n",
        "    for folder in os.listdir(filepath):\n",
        "        files = os.listdir(filepath+'/'+folder)\n",
        "        for file in files:\n",
        "            direc = filepath+'/'+folder+'/'+file\n",
        "            if 'mask' in direc: mask_direcs.append(direc)\n",
        "            else: img_direcs.append(direc)\n",
        "    return img_direcs, mask_direcs\n",
        "\n",
        "\n",
        "def get_img_transform(train=False, image_size=224, crop=False, jitter=0):\n",
        "    mean = [0.5]\n",
        "    std = [0.5]\n",
        "    if train:\n",
        "        if crop:\n",
        "            img_transform = [transforms.ToPILImage(),transforms.RandomResizedCrop(image_size, scale=[0.8, 1.0])]\n",
        "        else:\n",
        "            img_transform = [transforms.ToPILImage(),transforms.Resize((image_size, image_size))]\n",
        "        if jitter > 0:\n",
        "            img_transform.append(transforms.ColorJitter(brightness=jitter,\n",
        "                                                        contrast=jitter,\n",
        "                                                        saturation=jitter,\n",
        "                                                        hue=min(0.5, jitter)))\n",
        "        img_transform += [transforms.RandomHorizontalFlip(),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize(mean, std)]\n",
        "        img_transform = transforms.Compose(img_transform)\n",
        "    else:\n",
        "        img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "    return img_transform\n",
        "\n",
        "def get_label_transform(train=False, image_size=224, crop=False, jitter=0):\n",
        "    mean = [0.5]\n",
        "    std = [0.5]\n",
        "    if train:\n",
        "        if crop:\n",
        "            label_transform = [transforms.ToPILImage(),transforms.RandomResizedCrop(image_size, scale=[0.8, 1.0])]\n",
        "        else:\n",
        "            label_transform = [transforms.ToPILImage(),transforms.Resize((image_size, image_size))]\n",
        "        if jitter > 0:\n",
        "            label_transform.append(transforms.ColorJitter(brightness=jitter,\n",
        "                                                        contrast=jitter,\n",
        "                                                        saturation=jitter,\n",
        "                                                        hue=min(0.5, jitter)))\n",
        "        label_transform += [transforms.RandomHorizontalFlip(),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize(mean, std)]\n",
        "        label_transform = transforms.Compose(label_transform)\n",
        "    else:\n",
        "        label_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "    return label_transform\n",
        "    \n",
        "\n",
        "def get_pre_transform(image_size=224, crop=False, jitter=0):\n",
        "    if crop:\n",
        "        img_transform = [transforms.ToPILImage(), transforms.RandomResizedCrop(image_size, scale=[0.8, 1.0])]\n",
        "    else:\n",
        "        img_transform = [transforms.ToPILImage(), transforms.Resize((image_size, image_size))]\n",
        "    if jitter > 0:\n",
        "        img_transform.append(transforms.ColorJitter(brightness=jitter,\n",
        "                                                    contrast=jitter,\n",
        "                                                    saturation=jitter,\n",
        "                                                    hue=min(0.5, jitter)))\n",
        "    img_transform += [transforms.RandomHorizontalFlip(), lambda x: np.asarray(x)]\n",
        "    img_transform = transforms.Compose(img_transform)\n",
        "    return img_transform\n",
        "\n",
        "def get_post_transform(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    img_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "    return img_transform\n",
        "\n",
        "def colorful_spectrum_mix(img1, img2, alpha, ratio=1.0):\n",
        "    \"\"\"Input image size: ndarray of [H, W, C]\"\"\"\n",
        "    lam = np.random.uniform(0, alpha)\n",
        "\n",
        "    assert img1.shape == img2.shape\n",
        "    h, w, c = img1.shape\n",
        "    h_crop = int(h * sqrt(ratio))\n",
        "    w_crop = int(w * sqrt(ratio))\n",
        "    h_start = h // 2 - h_crop // 2\n",
        "    w_start = w // 2 - w_crop // 2\n",
        "\n",
        "    img1_fft = np.fft.fft2(img1, axes=(0, 1))\n",
        "    img2_fft = np.fft.fft2(img2, axes=(0, 1))\n",
        "    img1_abs, img1_pha = np.abs(img1_fft), np.angle(img1_fft)\n",
        "    img2_abs, img2_pha = np.abs(img2_fft), np.angle(img2_fft)\n",
        "\n",
        "    img1_abs = np.fft.fftshift(img1_abs, axes=(0, 1))\n",
        "    img2_abs = np.fft.fftshift(img2_abs, axes=(0, 1))\n",
        "\n",
        "    img1_abs_ = np.copy(img1_abs)\n",
        "    img2_abs_ = np.copy(img2_abs)\n",
        "    img1_abs[h_start:h_start + h_crop, w_start:w_start + w_crop] = \\\n",
        "        lam * img2_abs_[h_start:h_start + h_crop, w_start:w_start + w_crop] + (1 - lam) * img1_abs_[\n",
        "                                                                                          h_start:h_start + h_crop,\n",
        "                                                                                          w_start:w_start + w_crop]\n",
        "    img2_abs[h_start:h_start + h_crop, w_start:w_start + w_crop] = \\\n",
        "        lam * img1_abs_[h_start:h_start + h_crop, w_start:w_start + w_crop] + (1 - lam) * img2_abs_[\n",
        "                                                                                          h_start:h_start + h_crop,\n",
        "                                                                                          w_start:w_start + w_crop]\n",
        "\n",
        "    img1_abs = np.fft.ifftshift(img1_abs, axes=(0, 1))\n",
        "    img2_abs = np.fft.ifftshift(img2_abs, axes=(0, 1))\n",
        "\n",
        "    img21 = img1_abs * (np.e ** (1j * img1_pha))\n",
        "    img12 = img2_abs * (np.e ** (1j * img2_pha))\n",
        "    img21 = np.real(np.fft.ifft2(img21, axes=(0, 1)))\n",
        "    img12 = np.real(np.fft.ifft2(img12, axes=(0, 1)))\n",
        "    img21 = np.uint8(np.clip(img21, 0, 255))\n",
        "    img12 = np.uint8(np.clip(img12, 0, 255))\n",
        "\n",
        "    return img21, img12"
      ],
      "metadata": {
        "id": "Kyu2yCvnsAnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 1.1 Data Read(Fourier) & Load "
      ],
      "metadata": {
        "id": "dBgSpAIZIh-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DGDataset(Dataset):\n",
        "    def __init__(self, names, labels, transformer=None):\n",
        "        self.names = names\n",
        "        self.labels = labels\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.names[index]\n",
        "        mask_name = self.labels[index]\n",
        "        img = cv2.imread(img_name)\n",
        "        mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
        "        if self.transformer is not None:\n",
        "            img = self.transformer(img)\n",
        "            mask = self.transformer(mask)\n",
        "        return img, mask\n",
        "\n",
        "class FourierDGDataset(Dataset):\n",
        "    def __init__(self, names, labels, transformer=None, lbl_transformer=None, from_domain=None, alpha=1.0):\n",
        "        self.names = names\n",
        "        self.labels = labels\n",
        "        self.transformer = transformer\n",
        "        self.lbl_transformer = lbl_transformer\n",
        "        self.post_transform = get_post_transform()\n",
        "        self.from_domain = from_domain\n",
        "        self.alpha = alpha\n",
        "        \n",
        "        self.flat_names = []\n",
        "        self.flat_labels = []\n",
        "        self.flat_domains = []\n",
        "        for i in range(len(names)):\n",
        "            self.flat_domains += [i] * len(names[i])\n",
        "            self.flat_names += names[i]\n",
        "            self.flat_labels += labels[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.names[index]\n",
        "        mask_name = self.labels[index]\n",
        "        img = cv2.imread(img_name)\n",
        "        mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
        "        img_o = self.transformer(img)\n",
        "        mask_o = self.lbl_transformer(mask)\n",
        "\n",
        "        img_s, mask_s, _ = self.sample_image()  ## random pick image\n",
        "        img_s2o, img_o2s = colorful_spectrum_mix(img_o, img_s, alpha=self.alpha)  ## mix their amplitude\n",
        "        img_o, img_s = self.post_transform(img_o), self.post_transform(img_s)\n",
        "        img_s2o, img_o2s = self.post_transform(img_s2o), self.post_transform(img_o2s)\n",
        "        img = [img_o, img_s, img_s2o, img_o2s]  ## [original, img2, img1 x img2, img2 x img1] \n",
        "        mask = [mask_o, mask_s, mask_o, mask_s]\n",
        "        # domain = [domain, domain_s, domain, domain_s]\n",
        "        return img, mask\n",
        "\n",
        "    def sample_image(self, domain=None):\n",
        "        if self.from_domain == 'all':\n",
        "            domain_idx = randpy.randint(0, len(self.names)-1)\n",
        "        elif self.from_domain == 'inter':\n",
        "            domains = list(range(len(self.names)))\n",
        "            # domains.remove(domain)\n",
        "            domain_idx = randpy.sample(domains, 1)[0]\n",
        "        elif self.from_domain == 'intra':\n",
        "            domain_idx = domain\n",
        "        else:\n",
        "            raise ValueError(\"Not implemented\")\n",
        "        img_idx = randpy.randint(0, len(self.names[domain_idx])-1)\n",
        "        imgn_ame_sampled = self.names[img_idx]\n",
        "        img_sampled = cv2.imread(imgn_ame_sampled)\n",
        "        label_ame_sampled = self.labels[img_idx]\n",
        "        label_sampled = cv2.imread(label_ame_sampled, cv2.IMREAD_GRAYSCALE)\n",
        "        label_sampled = self.lbl_transformer(label_sampled)\n",
        "        return self.transformer(img_sampled), label_sampled, domain_idx\n",
        "\n",
        "\n",
        "def get_dataset(path, train=False, image_size=64, crop=False, jitter=0):\n",
        "    names, labels = dataset_info(path)\n",
        "    img_transform = get_img_transform(train, image_size, crop, jitter)\n",
        "    return DGDataset(names, labels, img_transform)\n",
        "\n",
        "def get_fourier_dataset(path, image_size=64, crop=False, jitter=0, from_domain='all', alpha=1.0):\n",
        "    names, labels = dataset_info(path)\n",
        "    img_transform = get_pre_transform(image_size, crop, jitter)\n",
        "    lbl_transform = get_label_transform(train=True, image_size=image_size, crop=crop, jitter=jitter)\n",
        "    return FourierDGDataset(names, labels, img_transform, lbl_transform, from_domain, alpha)"
      ],
      "metadata": {
        "id": "lpwjv5xjlfPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trian_path = \"./train\"\n",
        "val_path = \"./val\"\n",
        "test_path = \"./test\"\n",
        "\n",
        "train_fourier_dataset = get_fourier_dataset(path=train_path,crop=True,jitter=0.1)\n",
        "val_dataset = get_dataset(path=val_path, train=True,crop=True,jitter=0.1)\n",
        "test_dataset = get_dataset(path=test_path, train=True,crop=True,jitter=0.1)\n",
        "\n",
        "train_fourier_loader = torch.utils.data.DataLoader(train_fourier_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "print(f'Shape of image: {train_fourier_loader.dataset[0][0][0].numpy().shape}')\n",
        "print(f'Number of training batches: {len(train_fourier_loader)}')\n",
        "print(f'Number of validation batches: {len(val_loader)}')\n",
        "print(f'Number of test batches: {len(test_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKxmdpWZbMjd",
        "outputId": "6d274ac2-75ef-46e9-d876-80404f8f6de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of image: (3, 64, 64)\n",
            "Number of training batches: 66\n",
            "Number of validation batches: 17\n",
            "Number of test batches: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Build Model"
      ],
      "metadata": {
        "id": "3SL8XcjmAnQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unet2D"
      ],
      "metadata": {
        "id": "lQt5adIhPPIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load model\n",
        "Unet2D_model = smp.Unet(\n",
        "    encoder_name=\"resnet50\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=3,\n",
        ")"
      ],
      "metadata": {
        "id": "MxD7LCRxRf5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mean Teacher Model"
      ],
      "metadata": {
        "id": "O38A5I8dBnrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Teacher Model\n",
        "# Student model would be ResNet50 model\n",
        "class MeanTeacherModel(nn.Module):\n",
        "    # Core\n",
        "    def __init__(self, student_model, ema_decay):\n",
        "        super().__init__()\n",
        "        self.student_model = student_model\n",
        "        self.teacher_model = deepcopy(student_model)\n",
        "        self.ema_decay = ema_decay\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.student_model(x)\n",
        "\n",
        "    def update_teacher_model(self, current_epoch, momentum=0.9995):\n",
        "        momentum = min(1 - 1 / (current_epoch+1), self.ema_decay)\n",
        "        with torch.no_grad():\n",
        "            for student_params, teacher_params in zip(self.student_model.parameters(), self.teacher_model.parameters()):\n",
        "                teacher_params.data.mul_(momentum).add_((1 - momentum) * student_params.data)\n",
        "\n",
        "    # Adjust the weight of the consistency loss to rely on teacher's prediction\n",
        "    # The weight factor decreases from 1 to 0 during the first 15 epochs\n",
        "    def sigmoid_rampup(self, current_epoch):\n",
        "        current_epoch = np.clip(current_epoch, 0.0, 5.0)\n",
        "        phase = 1.0 - current_epoch / 5.0\n",
        "        return np.exp(-5.0 * phase * phase).astype(np.float32)\n",
        "\n",
        "    # The weight decreases from 100\n",
        "    def get_consistency_weight(self, epoch):\n",
        "        return 2.0 * self.sigmoid_rampup(epoch)"
      ],
      "metadata": {
        "id": "zkXkYCFGBdJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medical Image Metrics"
      ],
      "metadata": {
        "id": "wPIglb1nI4d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "\n",
        "    ## dice loss\n",
        "    def forward(self, logits, targets, smooth=1):\n",
        "        num = targets.size(0)\n",
        "        probs = logits\n",
        "        print(probs.shape)\n",
        "        print(targets.shape)\n",
        "        m1 = probs.view(num, -1)\n",
        "        m2 = targets.view(num, -1)\n",
        "        print(m1.shape)\n",
        "        print(m2.shape)\n",
        "        intersection = (m1 * m2)\n",
        " \n",
        "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
        "        return 1 - score.sum() / num\n",
        "\n",
        "    def dice_coeff(self, logits, targets):\n",
        "        return 1-(self.forward(logits, targets))"
      ],
      "metadata": {
        "id": "TmR0BSOXI26V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Training"
      ],
      "metadata": {
        "id": "j3_18EFUCceP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gpu_clean():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def train_mean_teacher(model, train_loader, val_loader, optimizer, consistency_criterion, supervised_criterion, device, epochs):\n",
        "    loss_train_list = []\n",
        "    acc_train_list = []\n",
        "    model.student_model.train()\n",
        "    model.teacher_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        ## Train\n",
        "        for it, (batch, label) in enumerate(train_loader):\n",
        "            gpu_clean()\n",
        "\n",
        "            batch = torch.cat(batch, dim=0).cuda()\n",
        "            label = torch.cat(label, dim=0).cuda()\n",
        "\n",
        "            # zero grad\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            total_loss_train = 0\n",
        "            super_loss_train = 0\n",
        "            const_loss_train = 0\n",
        "\n",
        "            # print(batch.shape)\n",
        "            # print(label.shape)\n",
        "            scores = model.student_model(batch)\n",
        "            with torch.no_grad():\n",
        "                scores_teacher = model.teacher_model(batch)\n",
        "            # scores = F.softmax(scores, dim=1)\n",
        "            # scores_teacher = F.softmax(scores_teacher, dim=1)\n",
        "\n",
        "            assert batch.size(0) % 2 == 0\n",
        "            split_idx = int(batch.size(0) / 2)\n",
        "            scores_ori, scores_aug = torch.split(scores, split_idx)\n",
        "            scores_ori_tea, scores_aug_tea = torch.split(scores_teacher, split_idx)\n",
        "            scores_ori_tea, scores_aug_tea = scores_ori_tea.detach(), scores_aug_tea.detach()\n",
        "            labels_ori, labels_aug = torch.split(label, split_idx)\n",
        "            print(labels_ori.shape)\n",
        "            assert scores_ori.size(0) == scores_aug.size(0)\n",
        "\n",
        "            # original data\n",
        "            # print(scores_ori.shape)\n",
        "            # for item in scores_ori[scores_ori > 0]:\n",
        "            #     print(item.item())\n",
        "            # print(labels_ori.shape)\n",
        "            # print(labels_ori[labels_ori > 0])\n",
        "            # print(labels_ori.to(torch.int64))\n",
        "            loss_cls = supervised_criterion(scores_ori, labels_ori.to(torch.int64))\n",
        "            # augmented data\n",
        "            loss_aug = supervised_criterion(scores_aug, labels_aug)\n",
        "\n",
        "            # calculate probability\n",
        "            p_ori, p_aug = F.softmax(scores_ori / 10.0, dim=1), F.softmax(scores_aug / 10.0, dim=1)\n",
        "            p_ori_tea, p_aug_tea = F.softmax(scores_ori_tea / 10.0, dim=1), F.softmax(scores_aug_tea / 10.0, dim=1)\n",
        "\n",
        "            # use KLD for consistency loss\n",
        "            loss_ori_tea = consistency_criterion(p_aug.log(), p_ori_tea, reduction='batchmean')\n",
        "            loss_aug_tea = consistency_criterion(p_ori.log(), p_aug_tea, reduction='batchmean')\n",
        "\n",
        "            # get consistency weight\n",
        "            const_weight = model.get_consistency_weight(epoch)\n",
        "\n",
        "            # calculate total loss\n",
        "            total_loss = 0.5 * loss_cls + 0.5 * loss_aug + \\\n",
        "                         const_weight * loss_ori_tea + const_weight * loss_aug_tea\n",
        "\n",
        "            # update\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        " \n",
        "            # Update teachers model parameters\n",
        "            model.update_teacher_model(current_epoch=epoch)\n",
        "            total_loss_train += total_loss.item()\n",
        "\n",
        "\n",
        "        loss_train_list.append(total_loss_train)\n",
        "        my_lr_scheduler.step()\n",
        "        print(\"Epoch [{}/{}], Loss: {:.4f}\".format(\n",
        "            epoch+1,epochs,\n",
        "            total_loss_train/len(train_loader),\n",
        "        ))\n",
        "\n",
        "\n",
        "    return model, loss_train_list\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "base_model = Unet2D_model\n",
        "base_model = base_model.cuda()\n",
        "\n",
        "mean_teacher_model = MeanTeacherModel(base_model, ema_decay=0.99)\n",
        "mean_teacher_model = mean_teacher_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(mean_teacher_model.parameters(), lr=0.0001)\n",
        "consistency_criterion = F.kl_div\n",
        "supervised_criterion = smp.losses.DiceLoss(mode='multilabel', classes=3)\n",
        "\n",
        "max_epoch = 2\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=max_epoch)\n",
        "mean_teacher_model, TRAIN_LOSS = train_mean_teacher(mean_teacher_model, train_fourier_loader, val_loader, \n",
        "                                                    optimizer, consistency_criterion, supervised_criterion, device, epochs=max_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "0f1zLnoeCWYv",
        "outputId": "a755eda1-a7c5-4d25-b238-cedf05a76cdd"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-e7fbea720774>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mmean_teacher_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanTeacherModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mema_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0mmean_teacher_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_teacher_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-e559b16a1d51>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, student_model, ema_decay)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudent_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mema_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(8,1,64,64)\n",
        "print(a.to(torch.int64))\n",
        "A = [a,a,a,a]\n",
        "final = torch.cat(A, dim=0)\n",
        "split_idx = int(final.size(0) / 2)\n",
        "final0, final1 = torch.split(final, split_idx)\n",
        "print(final0.shape)\n",
        "final0.reshape((16,64*64)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxGewnbroZx7",
        "outputId": "b6e70496-7d07-43f6-ed3f-8e9d9e36152f"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]])\n",
            "torch.Size([16, 1, 64, 64])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 4096])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ]
}