{"cells":[{"cell_type":"markdown","source":["### 1, Download and unzip data"],"metadata":{"id":"Hci3KvN7ivcH"}},{"cell_type":"code","source":["!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_Data.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_Data.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_GroundTruth.csv\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_GroundTruth.csv\n","!unzip \"./ISBI2016_ISIC_Part3_Test_Data.zip\"\n","!unzip \"./ISBI2016_ISIC_Part3_Training_Data.zip\""],"metadata":{"id":"ZXeyyLwuD6mr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install pytorch-lightning==1.8.1\n","# !pip install lightning-bolts\n","# !pip install --upgrade torch torchvision"],"metadata":{"id":"o9aCJwQKOAmg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import pytorch_lightning as pl\n","# from pl_bolts.models.self_supervised import FixMatch"],"metadata":{"id":"9KKGmk3SN3Ql"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2, Make training and test image folders by traning and test csv files"],"metadata":{"id":"RovDpxZFi-KA"}},{"cell_type":"code","source":["########## THIS CELL CAN ONLY RUN ONCE ##########\n","import os\n","import shutil\n","import pandas as pd\n","import numpy as np\n","\n","# Create train, unlabelled, val folders\n","if not os.path.exists(\"./train\"):\n","    os.makedirs(\"./train\")\n","    os.makedirs(\"./train/benign\")\n","    os.makedirs(\"./train/malignant\")\n","\n","if not os.path.exists(\"./unlabeled\"):\n","    os.makedirs(\"./unlabelled\")\n","    os.makedirs(\"./unlabelled/data\")\n","    os.makedirs(\"./unlabelled/benign\")\n","    os.makedirs(\"./unlabelled/malignant\")\n","\n","if not os.path.exists(\"./val\"):\n","    os.makedirs(\"./val\")\n","    os.makedirs(\"./val/benign\")\n","    os.makedirs(\"./val/malignant\")\n","\n","# Copy images to train, unlabelled, val folders\n","df = pd.read_csv(\"./ISBI2016_ISIC_Part3_Training_GroundTruth.csv\")\n","img_lis = []\n","lbl_lis = []\n","img_lis.append(\"ISIC_0000000\")\n","lbl_lis.append(\"benign\")\n","for i in range(len(df)):\n","    name, label = df[\"ISIC_0000000\"][i], df[\"benign\"][i]\n","    img_lis.append(name)\n","    lbl_lis.append(label)\n","\n","N_total = len(img_lis)\n","N_train = 270\n","N_unlabelled = 540\n","N_val = 90\n","print(f'Number of images: {N_total}')\n","print(f'Number of training images: {N_train}')\n","print(f'Number of unlabeled images: {N_unlabelled}')\n","print(f'Number of validation images: {N_val}')\n","\n","# Shuffle the data and split into train, unlabelled, val\n","shuffle_ix = np.random.permutation(np.arange(N_total))\n","ix_train = shuffle_ix[:N_train]\n","ix_unlabelled = shuffle_ix[N_train : N_train + N_unlabelled]\n","ix_val = shuffle_ix[N_train + N_unlabelled:]\n","\n","for i in ix_train:\n","    name, label = img_lis[i], lbl_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./train/\"+label+\"/\"+name+\".jpg\")\n","for i in ix_unlabelled:\n","    name = img_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./unlabelled/data/\"+name+\".jpg\")\n","for i in ix_val:\n","    name, label = img_lis[i], lbl_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./val/\"+label+\"/\"+name+\".jpg\")  \n","\n","# Create test folder\n","if not os.path.exists(\"./test\"):\n","    os.makedirs(\"./test\")\n","    os.makedirs(\"./test/benign\")\n","    os.makedirs(\"./test/malignant\")\n","df = pd.read_csv(\"./ISBI2016_ISIC_Part3_Test_GroundTruth.csv\")\n","shutil.copy(\"./ISBI2016_ISIC_Part3_Test_Data/ISIC_0000003.jpg\", \"./test/benign/ISIC_0000003.jpg\")\n","for i in range(len(df)):\n","    name, label = df[\"ISIC_0000003\"][i], df[\"0.0\"][i]\n","    label = \"benign\" if label == 0 else \"malignant\"\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Test_Data/\"+name+\".jpg\", \"./test/\"+label+\"/\"+name+\".jpg\")\n","print(f'Number of test images: {len(df)+1}')"],"metadata":{"id":"2WLrB9eWG3Nn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683817667214,"user_tz":-480,"elapsed":4227,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"f4687a14-2efa-4b22-be5d-90e05f5f8e56"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images: 900\n","Number of training images: 270\n","Number of unlabeled images: 540\n","Number of validation images: 90\n","Number of test images: 379\n"]}]},{"cell_type":"code","source":["import os, shutil, os.path\n","\n","train_ben = '/content/train/benign'\n","train_mal = '/content/train/malignant'\n","unlabelled = '/content/unlabelled/data'\n","val_ben = '/content/val/benign'\n","val_mal = '/content/val/malignant'\n","test_ben = '/content/test/benign'\n","test_mal = '/content/test/malignant'\n","\n","######## THIS IS FOR CLEAR ALL FOLDER USAGE ########\n","# folders = [train_ben, train_mal, unlabelled, val_ben, val_mal]\n","# for folder in folders:\n","  # for filename in os.listdir(folder):\n","  #     file_path = os.path.join(folder, filename)\n","  #     if os.path.isfile(file_path) or os.path.islink(file_path):\n","  #         os.unlink(file_path)\n","  #     elif os.path.isdir(file_path):\n","  #         shutil.rmtree(file_path)\n","\n","\n","_, _, files = next(os.walk(train_ben))\n","_, _, files1 = next(os.walk(train_mal))\n","print(len(files)+len(files1))\n","\n","_, _, files = next(os.walk(unlabelled))\n","print(len(files))\n","\n","_, _, files = next(os.walk(val_ben))\n","_, _, files1 = next(os.walk(val_mal))\n","print(len(files)+len(files1))\n","\n","_, _, files = next(os.walk(test_ben))\n","_, _, files1 = next(os.walk(test_mal))\n","print(len(files)+len(files1))"],"metadata":{"id":"507jS8z6D_Z1","executionInfo":{"status":"ok","timestamp":1683817718563,"user_tz":-480,"elapsed":396,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"128ef730-3277-418a-e5ab-3a0589dd796a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["270\n","540\n","90\n","379\n"]}]},{"cell_type":"markdown","source":["### 3.1, Build train, unlabelled, val loaders"],"metadata":{"id":"xqFLN7Lf79zv"}},{"cell_type":"code","source":["from torchvision.datasets import ImageFolder\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","import torch\n","\n","# Data augmentation for weak and strong versions\n","normalization = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","aug_normalization = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Create unlabelled dataset for ImageFolder problem\n","class UnlabelledDataset(Dataset):\n","    def __init__(self, root, transform=None):\n","        self.root = root\n","        self.transform = transform\n","        self.samples = self._gather_unlabelled_samples(root)\n","\n","    def _gather_unlabelled_samples(self, root):\n","        samples = []\n","        for filename in os.listdir(root):\n","            if filename.endswith(\".jpg\"):\n","                path = os.path.join(root, filename)\n","                samples.append((path, -1))  # -1 indicates no label is provided\n","        return samples\n","\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        img = Image.open(path).convert('RGB')\n","        img = self.transform(img) if self.transform is not None else img\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","# Load data\n","def dataloader(batch_size=12):\n","    train_dataset = ImageFolder('./train', transform=aug_normalization)\n","    loader_train = torch.utils.data.DataLoader(\n","        dataset=train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","\n","    unlabelled_dataset = UnlabelledDataset('./unlabelled/data', transform=normalization)\n","    loader_unlabelled = torch.utils.data.DataLoader(\n","        dataset=unlabelled_dataset,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","\n","    val_dataset = ImageFolder('./val', transform=normalization)\n","    loader_val = torch.utils.data.DataLoader(\n","        dataset=val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False\n","    )\n","    \n","    test_dataset = ImageFolder('./test', transform=normalization)\n","    loader_test = torch.utils.data.DataLoader(\n","        dataset=test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False\n","    )\n","\n","    return loader_train, loader_unlabelled, loader_val, loader_test\n","\n","batch_size = 12\n","loader_train, loader_unlabelled, loader_val, loader_test = dataloader(batch_size)\n","\n","print(f'Shape of image: {loader_train.dataset[0][0].shape}')\n","print(f'Number of training batches: {len(loader_train)}')\n","print(f'Number of unlabelled batches: {len(loader_unlabelled)}')\n","print(f'Number of validation batches: {len(loader_val)}')\n","print(f'Number of test batches: {len(loader_test)}')"],"metadata":{"id":"f-ChMb6Y8LEJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683817729719,"user_tz":-480,"elapsed":5261,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"877b73d1-439e-459b-f253-07d751a3f46a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of image: torch.Size([3, 224, 224])\n","Number of training batches: 23\n","Number of unlabelled batches: 45\n","Number of validation batches: 8\n","Number of test batches: 32\n"]}]},{"cell_type":"markdown","source":["### 3, Build training and test loaders"],"metadata":{"id":"B77B7mO0jw6K"}},{"cell_type":"code","source":["from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","import torch\n","\n","root_train = './train'\n","train_transform = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.RandomVerticalFlip(),       # using stronger augmentation functions to enhance performance or solve LT problem\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","root_val = './val'\n","root_test = './test'\n","test_transform = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","def get_train_test_set(batch_size=12):\n","    train_dataset = ImageFolder(root_train, transform=train_transform)\n","    loader_train = torch.utils.data.DataLoader(\n","        dataset=train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True\n","        )\n","    val_dataset = ImageFolder(root_val, transform=test_transform)\n","    loader_val = torch.utils.data.DataLoader(\n","        dataset=val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False\n","        )\n","    test_dataset = ImageFolder(root_test, transform=test_transform)\n","    loader_test = torch.utils.data.DataLoader(\n","        dataset=test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False\n","        )\n","    return loader_train, loader_val, loader_test\n","batch_size = 12\n","loader_train, loader_val, loader_test = get_train_test_set(batch_size)"],"metadata":{"id":"vizcUhavjvm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(loader_train))\n","print(len(loader_val))\n","print(len(loader_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdSwpMycDKXr","executionInfo":{"status":"ok","timestamp":1683728695174,"user_tz":-480,"elapsed":7,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"7359383a-f37f-48e5-cef8-2b2597a5e3d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23\n","53\n","32\n"]}]},{"cell_type":"markdown","source":["### 4, Build the network"],"metadata":{"id":"zrEdDAUPmJtt"}},{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models import resnet50\n","from torchsummary import summary\n","\n","# 3x3 Convolutional Layer\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","# Residual Block with 2 Convolutional Layers\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","# Residual Block with 3 Convolutional Layers\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","# Customized ResNet50 Model\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, use_fc=False, dropout=None):\n","        self.inplanes = 64\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.use_fc = use_fc\n","        self.use_dropout = True if dropout else False\n","        if self.use_fc:\n","            print('Using fc.')\n","            self.fc_add = nn.Linear(512*block.expansion, 512)\n","        if self.use_dropout:\n","            print('Using dropout.')\n","            self.dropout = nn.Dropout(p=dropout)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, *args):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = x.mean(dim=(-2, -1))\n","        x = x.view(x.size(0), -1)\n","        if self.use_fc:\n","            x = F.relu(self.fc_add(x))\n","        if self.use_dropout:\n","            x = self.dropout(x)\n","        return x\n","\n","# Get ResNet50 Model\n","def get_resnet50(pre_trained=True):\n","    Resnet50 = ResNet(Bottleneck, [3, 4, 6, 3], dropout=None)\n","    if pre_trained:\n","        pre_trained = resnet50(weights = \"IMAGENET1K_V2\").state_dict() \n","        new_weights = {k: pre_trained[k] for k in Resnet50.state_dict()}\n","        Resnet50.load_state_dict(new_weights)\n","    return Resnet50\n","\n","class Model(nn.Module):\n","    def __init__(self, encoder, num_classes=1):\n","        super(Model, self).__init__()\n","        self.encoder = encoder\n","        self.classifier = nn.Linear(2048, num_classes)\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.classifier(x)\n","        return x\n","    \n","resnet50 = get_resnet50(pre_trained=True)\n","model = Model(resnet50, 1)\n","\n","# Move the model to the GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Print the summary\n","input_size = (3, 224, 224)  # Input size for ResNet-50 model (channels, height, width)\n","# summary(model, input_size)"],"metadata":{"id":"ggxJrmzPmP8L","executionInfo":{"status":"ok","timestamp":1683817790522,"user_tz":-480,"elapsed":1695,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import copy\n","\n","class MeanTeacherModel(nn.Module):\n","    def __init__(self, student_model, ema_decay):\n","        super().__init__()\n","        self.student_model = student_model\n","        self.teacher_model = copy.deepcopy(student_model)\n","        self.ema_decay = ema_decay\n","\n","    def forward(self, x):\n","        return self.student_model(x)\n","\n","    def update_teacher_model(self):\n","        with torch.no_grad():\n","            for student_params, teacher_params in zip(self.student_model.parameters(), self.teacher_model.parameters()):\n","                teacher_params.data.mul_(self.ema_decay).add_((1 - self.ema_decay) * student_params.data)\n","\n","def train_mean_teacher(model, labeled_loader, unlabeled_loader, optimizer, consistency_criterion, supervised_criterion, device, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for (labeled_imgs, labeled_targets), (unlabeled_imgs, _) in zip(labeled_loader, unlabeled_loader):\n","            labeled_imgs = labeled_imgs.to(device)\n","            labeled_targets = labeled_targets.to(device)\n","            unlabeled_imgs = unlabeled_imgs.to(device)\n","            \n","            # Clear gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass of the student with labeled data\n","            labeled_preds = model.student_model(labeled_imgs)\n","            supervised_loss = supervised_criterion(labeled_preds, labeled_targets)\n","\n","            # Forward pass of the student and teacher with unlabeled data\n","            unlabeled_preds_student = model.student_model(unlabeled_imgs)\n","            with torch.no_grad():\n","                unlabeled_preds_teacher = model.teacher_model(unlabeled_imgs)\n","\n","            # Calculate consistency loss and total loss\n","            consistency_loss = consistency_criterion(unlabeled_preds_student, unlabeled_preds_teacher)\n","            loss = supervised_loss + consistency_loss\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Update teacher model parameters\n","            model.update_teacher_model()\n","\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(labeled_loader)}\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","student_model = model\n","student_model.to(device)\n","\n","mean_teacher_model = MeanTeacherModel(student_model, ema_decay=0.99)\n","mean_teacher_model.to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","consistency_criterion = nn.MSELoss()\n","supervised_criterion = nn.CrossEntropyLoss()\n","\n","train_mean_teacher(model, loader_train, loader_unlabelled, optimizer, consistency_criterion, supervised_criterion, device, epochs=1)"],"metadata":{"id":"fEkmU_zQ76oy","executionInfo":{"status":"ok","timestamp":1683817814004,"user_tz":-480,"elapsed":389,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### 5, Train and test your model"],"metadata":{"id":"5Q4AZq_enGEI"}},{"cell_type":"code","source":["from tqdm import tqdm\n","import numpy as np\n","import torch.nn as nn\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","max_epoch = 10\n","\n","# Loss function\n","class BCEFocalLoss(nn.Module):\n","    def __init__(self, gamma=2.0, alpha=0.6, reduction='mean'):\n","        super(BCEFocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.reduction = reduction\n","\n","    def forward(self, logits, target):\n","        alpha = self.alpha\n","        gamma = self.gamma\n","        loss = - alpha * (1 - logits) ** gamma * target * torch.log(logits) - \\\n","               (1 - alpha) * logits ** gamma * (1 - target) * torch.log(1 - logits)\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        return loss\n","\n","criterion = BCEFocalLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# Training\n","loss_train_list = []\n","loss_val_list = []\n","auc_train_list = []\n","auc_val_list = []\n","acc_train_list = []\n","acc_val_list = []\n","\n","for epoch in range(max_epoch):\n","    train_lbl, train_pred = [], []\n","    running_loss_train = 0.0\n","    print(\" -- Epoch {}/{}\".format(epoch + 1, max_epoch))\n","    model.train()\n","\n","    for data in tqdm(loader_train):\n","        optimizer.zero_grad()\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.float().to(device)\n","        outputs = model(images)[:,0]\n","        outputs = torch.sigmoid(outputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss_train += loss.item()\n","        y_scores = list(outputs.detach().cpu().numpy())\n","        y_true = list(labels.detach().cpu().numpy())\n","        train_lbl += y_true\n","        train_pred += y_scores\n","\n","    loss_train = running_loss_train / len(loader_train)\n","    loss_train_list.append(loss_train)\n","    train_lbl, train_pred = np.array(train_lbl), np.array(train_pred)\n","    train_pred_lbl = np.around(train_pred) # pred >= 0.5 pred_lbl = 1 else pred_lbl = 0\n","    train_auc = roc_auc_score(train_lbl, train_pred)\n","    train_acc = accuracy_score(train_lbl, train_pred_lbl)\n","    auc_train_list.append(train_auc)\n","    acc_train_list.append(train_acc)\n","    \n","    # Validation\n","    model.eval()\n","    val_lbl, val_pred = [], []\n","    running_loss_val = 0.0\n","\n","    for data in loader_val:\n","        val_images, val_labels = data\n","        val_images = val_images.to(device)\n","        val_labels = val_labels.float().to(device)\n","        val_outputs = model(val_images)[:, 0]\n","        val_outputs = torch.sigmoid(val_outputs)\n","        val_loss = criterion(val_outputs, val_labels)\n","        \n","        running_loss_val += val_loss.item()\n","        y_scores = list(val_outputs.detach().cpu().numpy())\n","        y_true = list(val_labels.detach().cpu().numpy())\n","        val_lbl += y_true\n","        val_pred += y_scores\n","        \n","    loss_val = running_loss_val / len(loader_val)\n","    loss_val_list.append(loss_val)\n","    val_lbl, val_pred = np.array(val_lbl), np.array(val_pred)\n","    val_pred_lbl = np.around(val_pred) # pred >= 0.5 pred_lbl = 1 else pred_lbl = 0\n","    val_auc = roc_auc_score(val_lbl, val_pred)\n","    val_acc = accuracy_score(val_lbl, val_pred_lbl)\n","    auc_val_list.append(val_auc)\n","    acc_val_list.append(val_acc)\n","    print(loss_train, loss_val, train_auc, val_auc)\n","\n","# Evaluation\n","model.eval()\n","test_lbl, test_pred = [], []\n","\n","for data in loader_test:\n","    test_images, test_labels = data\n","    test_images = test_images.to(device)\n","    test_labels = test_labels.float().to(device)\n","    test_outputs = model(test_images)[:, 0]\n","    test_outputs = torch.sigmoid(test_outputs)\n","    y_scores = list(test_outputs.detach().cpu().numpy())\n","    y_true = list(test_labels.detach().cpu().numpy())\n","    test_lbl += y_true\n","    test_pred += y_scores\n","        \n","test_lbl, test_pred = np.array(test_lbl), np.array(test_pred)\n","test_pred_lbl = np.around(test_pred) # pred >= 0.5 pred_lbl = 1 else pred_lbl = 0\n","test_auc = roc_auc_score(test_lbl, test_pred)\n","test_acc = accuracy_score(test_lbl, test_pred_lbl)\n","print(test_auc, test_acc)"],"metadata":{"id":"vfSsJ4AbnEID"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6, plot your training and test curves"],"metadata":{"id":"HlKYDx8JI4_M"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot loss curve\n","fig = plt.figure()\n","plt.plot(loss_train_list, label='Training Loss')\n","plt.plot(loss_val_list, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Loss Curve')\n","plt.legend()\n","plt.show()\n","\n","# Plot accuracy curve\n","fig = plt.figure()\n","plt.plot(acc_train_list, label='Training Accuracy')\n","plt.plot(acc_val_list, label='Validation Accuracy')\n","plt.axhline(y=test_acc, color='r', linestyle='--', label='Test Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy Curve')\n","plt.legend()\n","plt.show()\n","\n","# Plot AUC curve\n","fig = plt.figure()\n","plt.plot(auc_train_list, label='Training AUC')\n","plt.plot(auc_val_list, label='Validation AUC')\n","plt.axhline(y=test_auc, color='r', linestyle='--', label='Test AUC')\n","plt.xlabel('Epoch')\n","plt.ylabel('AUC')\n","plt.title('AUC Curve')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"PB3pjrhWneY_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1DLtw9mX04n0VIn7RPIrnJafnEyfX_CoY","timestamp":1683711057979},{"file_id":"https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022-labs/blob/main/lab02/notebooks/lab02b_cnn.ipynb","timestamp":1676776020914}],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"0f056848cf5d2396a4970b625f23716aa539c2ff5334414c1b5d98d7daae66f6"}}},"nbformat":4,"nbformat_minor":0}