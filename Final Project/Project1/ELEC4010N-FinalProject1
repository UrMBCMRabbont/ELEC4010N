{"cells":[{"cell_type":"code","source":["# Standard library imports\n","import os\n","import shutil\n","import math\n","import copy\n","import random\n","import gc\n","\n","# Third-party imports for data handling and scientific computation\n","import cv2\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","import albumentations as Augm\n","from albumentations.pytorch import ToTensorV2\n","from albumentations.augmentations.transforms import ColorJitter, FancyPCA\n","\n","# PyTorch imports for deep learning\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD\n","from torch.optim.lr_scheduler import StepLR, ExponentialLR\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","import torchvision.models as models\n","from torchvision.models import resnet50 as _resnet50\n","from torchsummary import summary\n","\n","# Other utilities\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"1pYsgb1hWbbr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684040450899,"user_tz":-480,"elapsed":7835,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"5c7dba9b-65f4-4137-8812-66e86b8098a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"Hci3KvN7ivcH"},"source":["### 1, Download and unzip data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXeyyLwuD6mr"},"outputs":[],"source":["!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_Data.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_Data.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_GroundTruth.csv\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_GroundTruth.csv\n","!unzip \"./ISBI2016_ISIC_Part3_Test_Data.zip\"\n","!unzip \"./ISBI2016_ISIC_Part3_Training_Data.zip\"\n","\n","## Augmentation\n","!pip install -U albumentations"]},{"cell_type":"markdown","metadata":{"id":"RovDpxZFi-KA"},"source":["### 2,   1/4 Times: Random Split Training and Test Dataset"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"2WLrB9eWG3Nn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684055092422,"user_tz":-480,"elapsed":11138,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"dc94166e-2303-4dc8-be97-ee9b9a869230"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images: 900\n","Number of training images: 270\n","Number of unlabeled images: 540\n","Number of validation images: 90\n","Number of test images: 379\n"]}],"source":["########## ONLY RUN THIS CELL CAN ONCE ##########\n","# Remove if exists, and create train, unlabeled val, test folders\n","train_path = \"./train\"\n","unlabeled_path = \"./unlabeled\"\n","val_path = \"./val\"\n","test_path = \"./test\"\n","\n","for path in [train_path, unlabeled_path, val_path, test_path]:\n","    if os.path.exists(path):\n","        shutil.rmtree(path)\n","    os.makedirs(path)\n","\n","for path in [train_path, unlabeled_path, val_path, test_path]:\n","    os.makedirs(os.path.join(path, \"benign\"))\n","    os.makedirs(os.path.join(path, \"malignant\"))\n","\n","os.makedirs(os.path.join(unlabeled_path, \"data\"))\n","\n","# Copy images to train, unlabeled, val folders\n","df = pd.read_csv(\"./ISBI2016_ISIC_Part3_Training_GroundTruth.csv\")\n","img_lis = []\n","lbl_lis = []\n","img_lis.append(\"ISIC_0000000\")\n","lbl_lis.append(\"benign\")\n","for i in range(len(df)):\n","    name, label = df[\"ISIC_0000000\"][i], df[\"benign\"][i]\n","    img_lis.append(name)\n","    lbl_lis.append(label)\n","\n","# Define the number of images in each category\n","N_total = len(img_lis)\n","N_train = 270\n","N_unlabeled = 540\n","\n","# Shuffle the data and split into train, unlabeled, val\n","shuffle_ix = np.random.permutation(np.arange(N_total))\n","ix_train = shuffle_ix[:N_train]\n","ix_unlabeled = shuffle_ix[N_train : N_train + N_unlabeled]\n","ix_val = shuffle_ix[N_train + N_unlabeled:]\n","\n","for i in ix_train:\n","    name, label = img_lis[i], lbl_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./train/\"+label+\"/\"+name+\".jpg\")\n","for i in ix_unlabeled:\n","    name = img_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./unlabeled/data/\"+name+\".jpg\")\n","for i in ix_val:\n","    name, label = img_lis[i], lbl_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./val/\"+label+\"/\"+name+\".jpg\")  \n","\n","# Copy images to test folder\n","df = pd.read_csv(\"./ISBI2016_ISIC_Part3_Test_GroundTruth.csv\")\n","shutil.copy(\"./ISBI2016_ISIC_Part3_Test_Data/ISIC_0000003.jpg\", \"./test/benign/ISIC_0000003.jpg\")\n","for i in range(len(df)):\n","    name, label = df[\"ISIC_0000003\"][i], df[\"0.0\"][i]\n","    label = \"benign\" if label == 0 else \"malignant\"\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Test_Data/\"+name+\".jpg\", \"./test/\"+label+\"/\"+name+\".jpg\")\n","\n","# Print out the number of images in each folder\n","print(f'Number of images: {len(img_lis)}')\n","print(f'Number of training images: {len(ix_train)}')\n","print(f'Number of unlabeled images: {len(ix_unlabeled)}')\n","print(f'Number of validation images: {len(ix_val)}')\n","print(f'Number of test images: {len(df)+1}')"]},{"cell_type":"markdown","source":["### 3.1, Augmentation"],"metadata":{"id":"VfMlcU0ZBclG"}},{"cell_type":"code","source":["BenignTrain_direc = \"/content/train/benign\"\n","MaligTrain_direc = \"/content/train/malignant/\"\n","BenignVal_direc = \"/content/val/benign\"\n","MaligVal_direc = \"/content/val/malignant/\"\n","\n","## Train\n","BenignTrain_filepaths = sorted([os.path.join(BenignTrain_direc, f) for f in os.listdir(BenignTrain_direc)])\n","MaligTrain_filepaths = sorted([os.path.join(MaligTrain_direc, f) for f in os.listdir(MaligTrain_direc)])\n","images_filepaths = [*BenignTrain_filepaths, *MaligTrain_filepaths, *MaligTrain_filepaths]\n","TrainImages_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n","\n","## Validation\n","BenignVal_filepaths = sorted([os.path.join(BenignVal_direc, f) for f in os.listdir(BenignVal_direc)])\n","MaligVal_filepaths = sorted([os.path.join(MaligVal_direc, f) for f in os.listdir(MaligVal_direc)])\n","images_filepaths = [*BenignVal_filepaths, *MaligVal_filepaths, *MaligVal_filepaths]\n","ValImages_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n","\n","random.seed(42)\n","random.shuffle(TrainImages_filepaths)\n","random.shuffle(ValImages_filepaths)\n","n_AugTrain = len(TrainImages_filepaths)\n","n_AugVal = len(ValImages_filepaths)\n","print(n_AugTrain)\n","print(n_AugVal)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Io-PgG16BZRB","executionInfo":{"status":"ok","timestamp":1684055110054,"user_tz":-480,"elapsed":17633,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"e0fac3be-a530-4291-da28-4f31a9bf9cfd"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["323\n","108\n"]}]},{"cell_type":"code","source":["class AugmDataSet():\n","    def __init__(self, images_filepaths, transform=None):\n","        self.images_filepaths = images_filepaths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_filepaths)\n","\n","    def __getitem__(self, idx):\n","        image_filepath = self.images_filepaths[idx]\n","        image = cv2.imread(image_filepath)\n","        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"malignant\":\n","            label = 1.0\n","        else:\n","            label = 0.0\n","        if self.transform is not None:\n","            image = self.transform(image=image)[\"image\"]\n","        return image, label\n","\n","# Flipping\n","GEO = Augm.Compose([\n","    Augm.Resize(224, 224),\n","    Augm.RandomCrop(width=224, height=224),\n","    Augm.HorizontalFlip(p=1),\n","    Augm.RandomBrightnessContrast(p=0.1),\n","    ToTensorV2()\n","])\n","\n","# Color Jitter\n","COL = Augm.Compose([\n","    Augm.Resize(224, 224),\n","    Augm.RandomCrop(width=224, height=224),\n","    ColorJitter(),\n","    Augm.RandomBrightnessContrast(p=0.1),\n","    ToTensorV2()\n","])\n","\n","# PCA\n","PCA = Augm.Compose([\n","    Augm.Resize(224, 224),\n","    Augm.RandomCrop(width=224, height=224),\n","    FancyPCA(),\n","    Augm.RandomBrightnessContrast(p=0.1),\n","    ToTensorV2()\n","])\n","\n","## Train\n","GEO_train_dataset = AugmDataSet(images_filepaths=TrainImages_filepaths, transform=GEO)\n","COL_train_dataset = AugmDataSet(images_filepaths=TrainImages_filepaths, transform=COL)\n","PCA_train_dataset = AugmDataSet(images_filepaths=TrainImages_filepaths, transform=PCA)\n","## Validation\n","GEO_val_dataset = AugmDataSet(images_filepaths=ValImages_filepaths, transform=GEO)\n","COL_val_dataset = AugmDataSet(images_filepaths=ValImages_filepaths, transform=COL)\n","PCA_val_dataset = AugmDataSet(images_filepaths=ValImages_filepaths, transform=PCA)"],"metadata":{"id":"HAOAJgK-C-IA","executionInfo":{"status":"ok","timestamp":1684055110054,"user_tz":-480,"elapsed":3,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqFLN7Lf79zv"},"source":["\n","### 3.2, Build train, unlabeled, val loaders"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684055110054,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"},"user_tz":-480},"id":"f-ChMb6Y8LEJ","outputId":"b577aabc-24e9-4a45-903f-b966d4023923"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of image: torch.Size([3, 224, 224])\n","Number of training batches: 39\n","Number of unlabeled batches: 17\n","Number of validation batches: 3\n","Number of test batches: 12\n"]}],"source":["# Data augmentation for weak and strong versions\n","normalization = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","aug_normalization = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomHorizontalFlip(),\n","    # transforms.ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=0.65, std=0.5)\n","])\n","\n","# Create unlabeled dataset for ImageFolder problem\n","class unlabeledDataset(Dataset):\n","    def __init__(self, root, transform=None):\n","        self.root = root\n","        self.transform = transform\n","        self.samples = self._gather_unlabeled_samples(root)\n","\n","    def _gather_unlabeled_samples(self, root):\n","        samples = []\n","        for filename in os.listdir(root):\n","            if filename.endswith(\".jpg\"):\n","                path = os.path.join(root, filename)\n","                samples.append((path, -1))  # -1 indicates no label is provided\n","        return samples\n","\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        img = Image.open(path).convert('RGB')\n","        img = self.transform(img) if self.transform is not None else img\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","# Load data in batches\n","def dataloader(batch_size=12, Aug_Train_dataset=None, Aug_Val_dataset=None):\n","    if Aug_Train_dataset != None:\n","        #### Gen & Aug Train data ####\n","        Augm_train_subset = []\n","        UnAugm_train_dataset = ImageFolder(\"./train\", transform=normalization)\n","        n_UnAugm_train = int(len(UnAugm_train_dataset))       ## 270\n","        n_Augm_train = n_AugTrain                                     ## change accordingly                  \n","\n","        ## split & combine train dataset\n","        UnAugm_train_subset = torch.utils.data.Subset(UnAugm_train_dataset, range(n_UnAugm_train))\n","        for dataset in Aug_Train_dataset:\n","            Augm_train_subset.append(torch.utils.data.Subset(dataset, range(n_Augm_train)))\n","        train_dataset = torch.utils.data.ConcatDataset([UnAugm_train_subset, Augm_train_subset[0],\n","                                                        Augm_train_subset[1], Augm_train_subset[2]])\n","    else:\n","        train_dataset = ImageFolder('./train', transform=aug_normalization)\n","    \n","    if Aug_Val_dataset != None:     \n","        #### Gen & Aug Validation data ####\n","        Augm_val_subset = []\n","        UnAugm_val_dataset = ImageFolder(\"./val\", transform=normalization)\n","        n_UnAugm_val = int(len(UnAugm_val_dataset))       ## 270\n","        n_Augm_val = n_AugVal                                     ## change accordingly                  \n","\n","        ## split & combine Validation dataset\n","        UnAugm_val_subset = torch.utils.data.Subset(UnAugm_val_dataset, range(n_UnAugm_val))\n","        for dataset in Aug_Val_dataset:\n","            Augm_val_subset.append(torch.utils.data.Subset(dataset, range(n_Augm_val)))\n","        val_dataset = torch.utils.data.ConcatDataset([UnAugm_val_dataset, Augm_val_subset[0],\n","                                                        Augm_val_subset[1], Augm_val_subset[2]])\n","    else:\n","        val_dataset = ImageFolder('./val', transform=normalization)\n","\n","    unlabeled_dataset = unlabeledDataset('./unlabeled/data', transform=normalization)\n","    test_dataset = ImageFolder('./test', transform=normalization)\n","    \n","    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","    unlabeled_loader = DataLoader(dataset=unlabeled_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, unlabeled_loader, val_loader, test_loader\n","\n","batch_size = 32\n","AUG_TYPE_LIST = [GEO_train_dataset, COL_train_dataset, PCA_train_dataset]\n","train_loader, unlabeled_loader, val_loader, test_loader = dataloader(batch_size, Aug_Train_dataset=AUG_TYPE_LIST)\n","\n","# Checkpoint\n","print(f'Shape of image: {train_loader.dataset[0][0].shape}')        #[3, 224, 224]\n","print(f'Number of training batches: {len(train_loader)}')           #23\n","print(f'Number of unlabeled batches: {len(unlabeled_loader)}')      #45\n","print(f'Number of validation batches: {len(val_loader)}')           #8\n","print(f'Number of test batches: {len(test_loader)}')                #32"]},{"cell_type":"markdown","metadata":{"id":"zrEdDAUPmJtt"},"source":["### 4, Build the network"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"ggxJrmzPmP8L","executionInfo":{"status":"ok","timestamp":1684053156105,"user_tz":-480,"elapsed":459,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}}},"outputs":[],"source":["# 3x3 Convolutional Layer\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","# Basic Block with 2 Convolutional Layers\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","# Bottleneck Block with 3 Convolutional Layers\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","# Customized ResNet Architecture\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, use_fc=False, dropout=None):\n","        self.inplanes = 64\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.use_fc = use_fc\n","        self.use_dropout = True if dropout else False\n","        if self.use_fc:\n","            print('Using fc.')\n","            self.fc_add = nn.Linear(512*block.expansion, 512)\n","        if self.use_dropout:\n","            print('Using dropout.')\n","            self.dropout = nn.Dropout(p=dropout)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, *args):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = x.mean(dim=(-2, -1))\n","        x = x.view(x.size(0), -1)\n","        if self.use_fc:\n","            x = F.relu(self.fc_add(x))\n","        if self.use_dropout:\n","            x = self.dropout(x)\n","        return x\n","\n","# Create ResNet50 Model with / without Pre-trained Weights and dropout\n","def get_resnet50(pre_trained=True):\n","    Resnet50 = ResNet(Bottleneck, [3, 4, 6, 3], dropout=0.5)\n","    if pre_trained:\n","        pre_trained_model = _resnet50(weights = \"IMAGENET1K_V2\")\n","        pre_trained = pre_trained_model.state_dict()\n","        new_weights = {k: pre_trained[k] for k in Resnet50.state_dict()}\n","        Resnet50.load_state_dict(new_weights)\n","    return Resnet50\n","\n","# Define the high-level model\n","class Model(nn.Module):\n","    def __init__(self, encoder, num_classes=1):\n","        super(Model, self).__init__()\n","        self.encoder = encoder\n","        self.classifier = nn.Linear(2048, num_classes)\n","        self.sigmoid = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.classifier(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","# Print the summary\n","input_size = (3, 224, 224)  # Input size for ResNet-50 model (channels, height, width)\n","#summary(model, input_size)"]},{"cell_type":"markdown","source":["### 5.1, 1/4 Times: Train Model"],"metadata":{"id":"8w2E_wZuPiC-"}},{"cell_type":"code","source":["def gpu_clean():\n","    gc.collect()\n","    torch.cuda.empty_cache()"],"metadata":{"id":"IcZzpeBpUOFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fEkmU_zQ76oy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23680c35-b1c1-46cd-dd4d-fa4537ba200a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using dropout.\n","Epoch [1/25], Loss: 0.0305, Unlabeled Train Acc: 61.6667%, Unlabeled Train AUC: 0.6743, Val Acc: 77.7778%, Val AUC: 0.5494\n","Epoch [2/25], Loss: 0.0245, Unlabeled Train Acc: 67.2222%, Unlabeled Train AUC: 0.6667, Val Acc: 72.2222%, Val AUC: 0.5548\n","Epoch [3/25], Loss: 0.0176, Unlabeled Train Acc: 71.8519%, Unlabeled Train AUC: 0.7234, Val Acc: 77.7778%, Val AUC: 0.6281\n","Epoch [4/25], Loss: 0.0132, Unlabeled Train Acc: 75.0000%, Unlabeled Train AUC: 0.7553, Val Acc: 70.0000%, Val AUC: 0.6049\n","Epoch [5/25], Loss: 0.0095, Unlabeled Train Acc: 80.0000%, Unlabeled Train AUC: 0.8156, Val Acc: 70.0000%, Val AUC: 0.6049\n","Epoch [6/25], Loss: 0.0091, Unlabeled Train Acc: 82.2222%, Unlabeled Train AUC: 0.8080, Val Acc: 68.8889%, Val AUC: 0.5764\n","Epoch [7/25], Loss: 0.0085, Unlabeled Train Acc: 81.1111%, Unlabeled Train AUC: 0.8450, Val Acc: 65.5556%, Val AUC: 0.5502\n"]}],"source":["class BCEFocalLoss(nn.Module):\n","    def __init__(self, gamma=2.0, alpha=0.6, reduction='mean'):\n","        super(BCEFocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.reduction = reduction\n","\n","    def forward(self, logits, target):\n","        alpha = self.alpha\n","        gamma = self.gamma\n","        loss = - alpha * (1 - logits) ** gamma * target * torch.log(logits) - \\\n","               (1 - alpha) * logits ** gamma * (1 - target) * torch.log(1 - logits)\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        return loss\n","        \n","class MeanTeacherModel(nn.Module):\n","    def __init__(self, student_model, ema_decay):\n","        super().__init__()\n","        self.student_model = student_model\n","        self.teacher_model = copy.deepcopy(student_model)\n","        self.ema_decay = ema_decay\n","\n","    def forward(self, x):\n","        return self.student_model(x)\n","\n","    def update_teacher_model(self):\n","        with torch.no_grad():\n","            for student_params, teacher_params in zip(self.student_model.parameters(), self.teacher_model.parameters()):\n","                teacher_params.data.mul_(self.ema_decay).add_((1-self.ema_decay) * student_params.data)\n","\n","    def sigmoid_rampup(self, current_epoch):\n","        current = np.clip(current_epoch, 0.0, 15.0)\n","        phase = 1.0 - current / 15.0\n","        return np.exp(-5.0 * phase * phase).astype(np.float32)\n","\n","    def get_consistency_weight(self, epoch):\n","        return 100 * self.sigmoid_rampup(epoch)\n","\n","\n","def train_mean_teacher(model, labeled_loader, unlabeled_loader, val_loader, optimizer, consistency_criterion, supervised_criterion, device, epochs):\n","    loss_train_list = []\n","    unlabeled_auc_train_list = []\n","    unlabeled_acc_train_list = []\n","    auc_val_list = []\n","    acc_val_list = []\n","    model.student_model.train()\n","    model.teacher_model.train()\n","    for epoch in range(epochs):\n","        gpu_clean()\n","        unlabeled_lbl, unlabeled_pred = [], [] ## for AUC\n","        total_loss_train = 0\n","        for (labeled_imgs, labeled_targets), (unlabeled_imgs, _) in zip(labeled_loader, unlabeled_loader):\n","            labeled_imgs = labeled_imgs.to(device)\n","            labeled_targets = labeled_targets.to(device)\n","            unlabeled_imgs = unlabeled_imgs.to(device)\n","            \n","            optimizer.zero_grad()\n","\n","            # Labeled data\n","            if labeled_imgs.dtype != torch.float32:\n","                labeled_imgs = labeled_imgs.float()\n","            labeled_preds = model.student_model(labeled_imgs)\n","            labeled_targets = labeled_targets.unsqueeze(1)\n","            labeled_targets = labeled_targets.float()\n","            supervised_loss = supervised_criterion(labeled_preds, labeled_targets)\n","\n","            # Unlabeled data\n","            unlabeled_preds_student = model.student_model(unlabeled_imgs)\n","            with torch.no_grad():\n","                unlabeled_preds_teacher = model.teacher_model(unlabeled_imgs)\n","            unlabeled_scores = list(unlabeled_preds_student.detach().cpu().numpy())\n","            unlabeled_true = list(np.around(unlabeled_preds_teacher.detach().cpu().numpy()))  ## make teacher outputs as binary label\n","            unlabeled_pred += unlabeled_scores\n","            unlabeled_lbl += unlabeled_true\n","\n","            # Consistency loss and total loss\n","            consistency_weights = model.get_consistency_weight(epoch)\n","            consistency_loss = consistency_weights * consistency_criterion(unlabeled_preds_student, unlabeled_preds_teacher) / batch_size   ## global var = 12\n","\n","            # Backward pass and optimization\n","            loss = supervised_loss + consistency_loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Update teacher model parameters\n","            model.update_teacher_model()\n","            total_loss_train += loss.item()\n","\n","        # Unlabeled metrics\n","        unlabeled_lbl, unlabeled_pred = np.array(unlabeled_lbl), np.array(unlabeled_pred)\n","        unlabeled_pred_lbl = np.around(unlabeled_pred)\n","        unlabeled_train_auc = roc_auc_score(unlabeled_lbl, unlabeled_pred)  ## sometime pred will all false\n","        unlabeled_train_acc = accuracy_score(unlabeled_lbl, unlabeled_pred_lbl)\n","        unlabeled_acc_train_list.append(unlabeled_train_acc)\n","        unlabeled_auc_train_list.append(unlabeled_train_auc)\n","\n","        # Validation\n","        gpu_clean()\n","        val_lbl, val_pred = [], [] ## for AUC\n","        for (imgs, targets) in val_loader:\n","            imgs = imgs.to(device)\n","            targets = targets.to(device)\n","\n","            if imgs.dtype != torch.float32:\n","                imgs = imgs.float()\n","            preds = model.student_model(imgs)\n","            targets = targets.unsqueeze(1)\n","            targets = targets.float()\n","\n","            val_scores = list(preds.detach().cpu().numpy())\n","            val_true = list(targets.detach().cpu().numpy())\n","            val_pred += val_scores\n","            val_lbl += val_true\n","        \n","        val_lbl, val_pred = np.array(val_lbl), np.array(val_pred)\n","        val_pred_lbl = np.around(val_pred)\n","        val_auc = roc_auc_score(val_lbl, val_pred)\n","        val_acc = accuracy_score(val_lbl, val_pred_lbl)\n","        acc_val_list.append(val_acc)\n","        auc_val_list.append(val_auc)\n","\n","        loss_train_list.append(total_loss_train)\n","        my_lr_scheduler.step()\n","        print(\"Epoch [{}/{}], Loss: {:.4f}, Unlabeled Train Acc: {:.4f}%, Unlabeled Train AUC: {:.4f}, Val Acc: {:.4f}%, Val AUC: {:.4f}\".format(\n","            epoch+1,epochs,\n","            total_loss_train/len(labeled_loader),\n","            unlabeled_acc_train_list[-1]*100,\n","            unlabeled_auc_train_list[-1],\n","            acc_val_list[-1]*100,\n","            auc_val_list[-1]\n","        ))\n","\n","\n","    return model, loss_train_list, unlabeled_acc_train_list, unlabeled_auc_train_list, acc_val_list, auc_val_list\n","\n","\n","resnet50 = get_resnet50(pre_trained=True)\n","model = Model(resnet50, 1)\n","model = model.cuda()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","student_model = model\n","student_model.to(device)\n","\n","mean_teacher_model = MeanTeacherModel(student_model, ema_decay=0.99)\n","mean_teacher_model.to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","consistency_criterion = nn.MSELoss()\n","supervised_criterion = BCEFocalLoss()\n","\n","max_epoch = 25\n","my_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=max_epoch)\n","mean_teacher_model, TRAIN_LOSS, UNLAB_ACC_TRAIN, UNLAB_AUC_TRAIN, ACC_VAL, AUC_VAL = train_mean_teacher(mean_teacher_model, train_loader, unlabeled_loader, val_loader, \n","                                                                                            optimizer, consistency_criterion, supervised_criterion, device, epochs=max_epoch)"]},{"cell_type":"markdown","metadata":{"id":"5Q4AZq_enGEI"},"source":["### 5.2, Test model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vfSsJ4AbnEID"},"outputs":[],"source":["# Evaluation\n","mean_teacher_model.eval()\n","test_lbl, test_pred = [], []\n","\n","for data in test_loader:\n","    test_images, test_labels = data\n","    test_images = test_images.to(device)\n","    test_labels = test_labels.float().to(device)\n","    test_outputs = mean_teacher_model.student_model(test_images)[:, 0]\n","    y_scores = list(test_outputs.detach().cpu().numpy())\n","    y_true = list(test_labels.detach().cpu().numpy())\n","    test_lbl += y_true\n","    test_pred += y_scores\n","        \n","test_lbl, test_pred = np.array(test_lbl), np.array(test_pred)\n","test_pred_lbl = np.around(test_pred) # pred >= 0.5 pred_lbl = 1 else pred_lbl = 0\n","test_auc = roc_auc_score(test_lbl, test_pred)\n","test_acc = accuracy_score(test_lbl, test_pred_lbl)\n","print(test_auc, test_acc)"]},{"cell_type":"markdown","metadata":{"id":"HlKYDx8JI4_M"},"source":["### 6, plot your training and test curves"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PB3pjrhWneY_"},"outputs":[],"source":["# Plot loss curve\n","fig = plt.figure()\n","plt.plot(TRAIN_LOSS, label='Training Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Loss Curve')\n","plt.legend()\n","plt.show()\n","\n","# Plot accuracy curve\n","fig = plt.figure()\n","plt.plot(UNLAB_ACC_TRAIN, label='Training Accuracy')\n","plt.plot(ACC_VAL, label='Validation Accuracy')\n","plt.axhline(y=test_acc, color='r', linestyle='--', label='Test Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy Curve')\n","plt.legend()\n","plt.show()\n","\n","# Plot AUC curve\n","fig = plt.figure()\n","plt.plot(UNLAB_AUC_TRAIN, label='Training AUC')\n","plt.plot(AUC_VAL, label='Validation AUC')\n","plt.axhline(y=test_auc, color='r', linestyle='--', label='Test AUC')\n","plt.xlabel('Epoch')\n","plt.ylabel('AUC')\n","plt.title('AUC Curve')\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1DLtw9mX04n0VIn7RPIrnJafnEyfX_CoY","timestamp":1683711057979},{"file_id":"https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022-labs/blob/main/lab02/notebooks/lab02b_cnn.ipynb","timestamp":1676776020914}],"gpuType":"V100"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"0f056848cf5d2396a4970b625f23716aa539c2ff5334414c1b5d98d7daae66f6"}}},"nbformat":4,"nbformat_minor":0}