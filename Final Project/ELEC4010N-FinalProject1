{"cells":[{"cell_type":"code","source":["# Standard library imports\n","import os\n","import shutil\n","import math\n","import copy\n","import gc\n","import random\n","\n","# Third-party imports for data handling and scientific computation\n","import cv2\n","import pandas as pd\n","import numpy as np\n","import albumentations as Augm\n","from albumentations.pytorch import ToTensorV2\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","# PyTorch imports for deep learning\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import ExponentialLR\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","import torchvision.models as models\n","from torchvision.models import resnet50 as _resnet50\n","from torchsummary import summary\n","\n","# Other utilities\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"],"metadata":{"id":"1pYsgb1hWbbr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hci3KvN7ivcH"},"source":["### 1, Download and unzip data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXeyyLwuD6mr"},"outputs":[],"source":["!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_Data.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_Data.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_GroundTruth.csv\n","!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_GroundTruth.csv\n","!unzip \"./ISBI2016_ISIC_Part3_Test_Data.zip\"\n","!unzip \"./ISBI2016_ISIC_Part3_Training_Data.zip\"\n","\n","## Augmentation\n","!pip install -U albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9aCJwQKOAmg"},"outputs":[],"source":["# !pip install pytorch-lightning==1.8.1\n","# !pip install lightning-bolts\n","# !pip install --upgrade torch torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KKGmk3SN3Ql"},"outputs":[],"source":["# import pytorch_lightning as pl\n","# from pl_bolts.models.self_supervised import FixMatch"]},{"cell_type":"markdown","metadata":{"id":"RovDpxZFi-KA"},"source":["### 2, Make training and test image folders by traning and test csv files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WLrB9eWG3Nn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683955362040,"user_tz":-480,"elapsed":2792,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"53d03384-9ccc-47bb-94cf-7fca1c09adfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images: 900\n","Number of training images: 270\n","Number of unlabeled images: 540\n","Number of validation images: 90\n","Number of test images: 379\n"]}],"source":["########## ONLY RUN THIS CELL CAN ONCE ##########\n","# Remove if exists, and create train, unlabeled val, test folders\n","train_path = \"./train\"\n","unlabeled_path = \"./unlabeled\"\n","val_path = \"./val\"\n","test_path = \"./test\"\n","\n","for path in [train_path, unlabeled_path, val_path, test_path]:\n","    if os.path.exists(path):\n","        shutil.rmtree(path)\n","    os.makedirs(path)\n","\n","for path in [train_path, unlabeled_path, val_path, test_path]:\n","    os.makedirs(os.path.join(path, \"benign\"))\n","    os.makedirs(os.path.join(path, \"malignant\"))\n","\n","os.makedirs(os.path.join(unlabeled_path, \"data\"))\n","\n","# Copy images to train, unlabeled, val folders\n","df = pd.read_csv(\"./ISBI2016_ISIC_Part3_Training_GroundTruth.csv\")\n","img_lis = []\n","lbl_lis = []\n","img_lis.append(\"ISIC_0000000\")\n","lbl_lis.append(\"benign\")\n","for i in range(len(df)):\n","    name, label = df[\"ISIC_0000000\"][i], df[\"benign\"][i]\n","    img_lis.append(name)\n","    lbl_lis.append(label)\n","\n","# Define the number of images in each category\n","N_total = len(img_lis)\n","N_train = 270\n","N_unlabeled = 540\n","\n","# Shuffle the data and split into train, unlabeled, val\n","shuffle_ix = np.random.permutation(np.arange(N_total))\n","ix_train = shuffle_ix[:N_train]\n","ix_unlabeled = shuffle_ix[N_train : N_train + N_unlabeled]\n","ix_val = shuffle_ix[N_train + N_unlabeled:]\n","\n","for i in ix_train:\n","    name, label = img_lis[i], lbl_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./train/\"+label+\"/\"+name+\".jpg\")\n","for i in ix_unlabeled:\n","    name = img_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./unlabeled/data/\"+name+\".jpg\")\n","for i in ix_val:\n","    name, label = img_lis[i], lbl_lis[i]\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Training_Data/\"+name+\".jpg\", \"./val/\"+label+\"/\"+name+\".jpg\")  \n","\n","# Copy images to test folder\n","df = pd.read_csv(\"./ISBI2016_ISIC_Part3_Test_GroundTruth.csv\")\n","shutil.copy(\"./ISBI2016_ISIC_Part3_Test_Data/ISIC_0000003.jpg\", \"./test/benign/ISIC_0000003.jpg\")\n","for i in range(len(df)):\n","    name, label = df[\"ISIC_0000003\"][i], df[\"0.0\"][i]\n","    label = \"benign\" if label == 0 else \"malignant\"\n","    shutil.copy(\"./ISBI2016_ISIC_Part3_Test_Data/\"+name+\".jpg\", \"./test/\"+label+\"/\"+name+\".jpg\")\n","\n","# Print out the number of images in each folder\n","print(f'Number of images: {len(img_lis)}')\n","print(f'Number of training images: {len(ix_train)}')\n","print(f'Number of unlabeled images: {len(ix_unlabeled)}')\n","print(f'Number of validation images: {len(ix_val)}')\n","print(f'Number of test images: {len(df)+1}')"]},{"cell_type":"markdown","source":["### 3.1, Augmentation"],"metadata":{"id":"VfMlcU0ZBclG"}},{"cell_type":"code","source":["BenignTrain_direc = \"/content/train/benign\"\n","MaligTrain_direc = \"/content/train/malignant/\"\n","\n","BenignTrain_filepaths = sorted([os.path.join(BenignTrain_direc, f) for f in os.listdir(BenignTrain_direc)])\n","MaligTrain_filepaths = sorted([os.path.join(MaligTrain_direc, f) for f in os.listdir(MaligTrain_direc)])\n","images_filepaths = [*MaligTrain_filepaths]  ## Aug both\n","TrainImages_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n","\n","random.seed(42)\n","random.shuffle(TrainImages_filepaths)\n","print(len(TrainImages_filepaths))  ## Later used for dataloader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Io-PgG16BZRB","executionInfo":{"status":"ok","timestamp":1683966966405,"user_tz":-480,"elapsed":1442,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"3edf6051-b51e-4de2-f8c2-e706c0562951"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["55\n"]}]},{"cell_type":"code","source":["class AugmDataSet():\n","    def __init__(self, images_filepaths, transform=None):\n","        self.images_filepaths = images_filepaths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_filepaths)\n","\n","    def __getitem__(self, idx):\n","        image_filepath = self.images_filepaths[idx]\n","        image = cv2.imread(image_filepath)\n","        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"malignant\":\n","            label = 1.0\n","        else:\n","            label = 0.0\n","        if self.transform is not None:\n","            image = self.transform(image=image)[\"image\"]\n","        return image, label\n","\n","\n","# Flipping\n","GEO = Augm.Compose([\n","    Augm.augmentations.geometric.resize.Resize(224, 224),\n","    Augm.RandomCrop(width=224, height=224),\n","    Augm.HorizontalFlip(p=1),\n","    Augm.RandomBrightnessContrast(p=0.1),\n","    ToTensorV2()\n","])\n","GEO_train_dataset = AugmDataSet(images_filepaths=TrainImages_filepaths, transform=GEO)\n","# Color distortion\n","COL = Augm.Compose([\n","    Augm.augmentations.geometric.resize.Resize(224, 224),\n","    Augm.RandomCrop(width=224, height=224),\n","    Augm.augmentations.transforms.ColorJitter(),\n","    Augm.RandomBrightnessContrast(p=0.1),\n","    ToTensorV2()\n","])\n","COL_train_dataset = AugmDataSet(images_filepaths=TrainImages_filepaths, transform=COL)\n","# PCA\n","PCA = Augm.Compose([\n","    Augm.augmentations.geometric.resize.Resize(224, 224),\n","    Augm.RandomCrop(width=224, height=224),\n","    Augm.augmentations.transforms.FancyPCA(),\n","    Augm.RandomBrightnessContrast(p=0.1),\n","    ToTensorV2()\n","])\n","PCA_train_dataset = AugmDataSet(images_filepaths=TrainImages_filepaths, transform=PCA)"],"metadata":{"id":"HAOAJgK-C-IA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqFLN7Lf79zv"},"source":["\n","### 3.2, Build train, unlabeled, val loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1683967185965,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"},"user_tz":-480},"id":"f-ChMb6Y8LEJ","outputId":"6ac81d1f-627e-4b1e-ddc3-9792571cdf99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of image: torch.Size([3, 224, 224])\n","Number of training batches: 37\n","Number of unlabeled batches: 45\n","Number of validation batches: 8\n","Number of test batches: 32\n"]}],"source":["# Data augmentation for weak and strong versions\n","normalization = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","aug_normalization = transforms.Compose([\n","    transforms.Resize(244),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomHorizontalFlip(),\n","    # transforms.ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=0.65, std=0.5)\n","])\n","\n","# Create unlabeled dataset for ImageFolder problem\n","class unlabeledDataset(Dataset):\n","    def __init__(self, root, transform=None):\n","        self.root = root\n","        self.transform = transform\n","        self.samples = self._gather_unlabeled_samples(root)\n","\n","    def _gather_unlabeled_samples(self, root):\n","        samples = []\n","        for filename in os.listdir(root):\n","            if filename.endswith(\".jpg\"):\n","                path = os.path.join(root, filename)\n","                samples.append((path, -1))  # -1 indicates no label is provided\n","        return samples\n","\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        img = Image.open(path).convert('RGB')\n","        img = self.transform(img) if self.transform is not None else img\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","# Load data in batches\n","def dataloader(batch_size=12, Aug_Train_dataset=None):\n","    if Aug_Train_dataset != None:\n","        #### Gen & Aug labeled data ####\n","        train_path = \"./train\"\n","        unlabeled_path = \"./unlabeled\"\n","        Augm_train_subset = []\n","        UnAugm_train_dataset = ImageFolder(train_path, transform=normalization)\n","        n_UnAugm_train = int(len(UnAugm_train_dataset))       ## 270\n","        n_Augm_train = 55                  \n","\n","        ## split & combine train dataset\n","        UnAugm_train_subset = torch.utils.data.Subset(UnAugm_train_dataset, range(n_UnAugm_train))\n","        for dataset in Aug_Train_dataset:\n","            Augm_train_subset.append(torch.utils.data.Subset(dataset, range(n_Augm_train)))\n","\n","        train_dataset = torch.utils.data.ConcatDataset([UnAugm_train_subset, Augm_train_subset[0],\n","                                                        Augm_train_subset[1], Augm_train_subset[2]])\n","    else: train_dataset = ImageFolder('./train', transform=aug_normalization)\n","    train_loader = torch.utils.data.DataLoader(\n","        dataset=train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","\n","    unlabeled_dataset = unlabeledDataset('./unlabeled/data', transform=normalization)\n","    unlabeled_loader = torch.utils.data.DataLoader(\n","        dataset=unlabeled_dataset,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","\n","    val_dataset = ImageFolder('./val', transform=normalization)\n","    val_loader = torch.utils.data.DataLoader(\n","        dataset=val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False\n","    )\n","    \n","    test_dataset = ImageFolder('./test', transform=normalization)\n","    test_loader = torch.utils.data.DataLoader(\n","        dataset=test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False\n","    )\n","\n","    return train_loader, unlabeled_loader, val_loader, test_loader\n","\n","batch_size = 12\n","train_loader, unlabeled_loader, val_loader, test_loader = dataloader(batch_size, Aug_Train_dataset=[GEO_train_dataset, COL_train_dataset, PCA_train_dataset])\n","\n","# Checkpoint\n","print(f'Shape of image: {train_loader.dataset[0][0].shape}')        #[3, 224, 224]\n","print(f'Number of training batches: {len(train_loader)}')           #23\n","print(f'Number of unlabeled batches: {len(unlabeled_loader)}')      #45\n","print(f'Number of validation batches: {len(val_loader)}')           #8\n","print(f'Number of test batches: {len(test_loader)}')                #32"]},{"cell_type":"markdown","metadata":{"id":"zrEdDAUPmJtt"},"source":["### 4, Build the network"]},{"cell_type":"code","execution_count":99,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1683970187312,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"},"user_tz":-480},"id":"ggxJrmzPmP8L"},"outputs":[],"source":["# 3x3 Convolutional Layer\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","# Basic Block with 2 Convolutional Layers\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","# Bottleneck Block with 3 Convolutional Layers\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","# Customized ResNet Architecture\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, use_fc=False, dropout=None):\n","        self.inplanes = 64\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.use_fc = use_fc\n","        self.use_dropout = True if dropout else False\n","        if self.use_fc:\n","            print('Using fc.')\n","            self.fc_add = nn.Linear(512*block.expansion, 512)\n","        if self.use_dropout:\n","            print('Using dropout.')\n","            self.dropout = nn.Dropout(p=dropout)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, *args):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = x.mean(dim=(-2, -1))\n","        x = x.view(x.size(0), -1)\n","        if self.use_fc:\n","            x = F.relu(self.fc_add(x))\n","        if self.use_dropout:\n","            x = self.dropout(x)\n","        return x\n","\n","# Create ResNet50 Model with / without Pre-trained Weights and dropout\n","def get_resnet50(pre_trained=True):\n","    Resnet50 = ResNet(Bottleneck, [3, 4, 6, 3], dropout=False)\n","    if pre_trained:\n","        pre_trained_model = _resnet50(weights = \"IMAGENET1K_V2\")\n","        pre_trained = pre_trained_model.state_dict()\n","        new_weights = {k: pre_trained[k] for k in Resnet50.state_dict()}\n","        Resnet50.load_state_dict(new_weights)\n","    return Resnet50\n","\n","# Define the high-level model\n","class Model(nn.Module):\n","    def __init__(self, encoder, num_classes=1):\n","        super(Model, self).__init__()\n","        self.encoder = encoder\n","        self.classifier = nn.Linear(2048, num_classes)\n","        self.sigmoid = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.classifier(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","# Print the summary\n","input_size = (3, 224, 224)  # Input size for ResNet-50 model (channels, height, width)\n","#summary(model, input_size)"]},{"cell_type":"markdown","source":["### 5.1, Trai Model"],"metadata":{"id":"8w2E_wZuPiC-"}},{"cell_type":"code","source":["def gpu_clean():\n","    gc.collect()\n","    torch.cuda.empty_cache()"],"metadata":{"id":"IcZzpeBpUOFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":101,"metadata":{"id":"fEkmU_zQ76oy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1683970242302,"user_tz":-480,"elapsed":35621,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}},"outputId":"e39488c8-53b0-426a-9acd-3932f5b7e41e"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAX:  [0.4969225]\n","MIN:  [0.42986125]\n","MAX:  [0.5312157]\n","MIN:  [0.4548077]\n","MAX:  [0.49978408]\n","MIN:  [0.4149624]\n","MAX:  [0.51211435]\n","MIN:  [0.45034903]\n","MAX:  [0.5285996]\n","MIN:  [0.4383399]\n","MAX:  [0.51919895]\n","MIN:  [0.45567387]\n","MAX:  [0.5395682]\n","MIN:  [0.4367729]\n","MAX:  [0.5198348]\n","MIN:  [0.4345385]\n","MAX:  [0.5549596]\n","MIN:  [0.4419172]\n","MAX:  [0.57255465]\n","MIN:  [0.45215914]\n","MAX:  [0.503154]\n","MIN:  [0.44514212]\n","MAX:  [0.5308733]\n","MIN:  [0.46600902]\n","MAX:  [0.53900075]\n","MIN:  [0.44451633]\n","MAX:  [0.5219545]\n","MIN:  [0.43560624]\n","MAX:  [0.55297285]\n","MIN:  [0.46758136]\n","MAX:  [0.52355546]\n","MIN:  [0.46229592]\n","MAX:  [0.53492755]\n","MIN:  [0.4124324]\n","MAX:  [0.5423613]\n","MIN:  [0.4503596]\n","MAX:  [nan]\n","MIN:  [nan]\n","MAX:  [nan]\n","MIN:  [nan]\n","MAX:  [nan]\n","MIN:  [nan]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-101-dde768629f8f>\u001b[0m in \u001b[0;36m<cell line: 157>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mmy_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExponentialLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m \u001b[0mmean_teacher_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNLAB_ACC_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNLAB_AUC_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACC_VAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC_VAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mean_teacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_teacher_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsistency_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupervised_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-101-dde768629f8f>\u001b[0m in \u001b[0;36mtrain_mean_teacher\u001b[0;34m(model, labeled_loader, unlabeled_loader, val_loader, optimizer, consistency_criterion, supervised_criterion, device, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0munlabeled_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m## for AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabeled_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munlabeled_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mlabeled_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeled_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mlabeled_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeled_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-cb7b9ebf5cc7>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \"\"\"\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class BCEFocalLoss(nn.Module):\n","    def __init__(self, gamma=2.0, alpha=0.6, reduction='mean'):\n","        super(BCEFocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.reduction = reduction\n","\n","    def forward(self, logits, target):\n","        alpha = self.alpha\n","        gamma = self.gamma\n","        loss = - alpha * (1 - logits) ** gamma * target * torch.log(logits) - \\\n","               (1 - alpha) * logits ** gamma * (1 - target) * torch.log(1 - logits)\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        return loss\n","        \n","class MeanTeacherModel(nn.Module):\n","    def __init__(self, student_model, ema_decay):\n","        super().__init__()\n","        self.student_model = student_model\n","        self.teacher_model = copy.deepcopy(student_model)\n","        self.ema_decay = ema_decay\n","\n","    def forward(self, x):\n","        return self.student_model(x)\n","\n","    def update_teacher_model(self, cur_epoch=None, max_epoch=None):\n","        with torch.no_grad():\n","            # ema_decay = cur_epoch/(max_epoch-1) * self.ema_decay\n","            for student_params, teacher_params in zip(self.student_model.parameters(), self.teacher_model.parameters()):\n","                teacher_params.data.mul_(self.ema_decay).add_((1-self.ema_decay) * student_params.data)\n","\n","    def sigmoid_rampup(self, current_epoch):\n","        current = np.clip(current_epoch, 0.0, 15.0)\n","        phase = 1.0 - current / 15.0\n","        return np.exp(-5.0 * phase * phase).astype(np.float32)\n","\n","    def get_consistency_weight(self, epoch):\n","        return 100 * self.sigmoid_rampup(epoch)\n","\n","\n","def train_mean_teacher(model, labeled_loader, unlabeled_loader, val_loader, optimizer, consistency_criterion, supervised_criterion, device, epochs):\n","    loss_train_list = []\n","    loss_val_list = []\n","    unlabeled_auc_train_list = []\n","    unlabeled_acc_train_list = []\n","    auc_val_list = []\n","    acc_val_list = []\n","    model.student_model.train()\n","    model.teacher_model.train()\n","    for epoch in range(epochs):\n","        gpu_clean()\n","        unlabeled_lbl, unlabeled_pred = [], [] ## for AUC\n","        total_loss = 0\n","        for (labeled_imgs, labeled_targets), (unlabeled_imgs, _) in zip(labeled_loader, unlabeled_loader):\n","            labeled_imgs = labeled_imgs.to(device)\n","            labeled_targets = labeled_targets.to(device)\n","            unlabeled_imgs = unlabeled_imgs.to(device)\n","            \n","            # Clear gradients\n","            optimizer.zero_grad()\n","\n","            # Labeled data\n","            labeled_preds = model.student_model(labeled_imgs)\n","            labeled_targets = labeled_targets.unsqueeze(1)\n","            labeled_targets = labeled_targets.float()\n","            supervised_loss = supervised_criterion(labeled_preds, labeled_targets)\n","\n","            # Unlabeled data\n","            unlabeled_preds_student = model.student_model(unlabeled_imgs)\n","            with torch.no_grad():\n","                unlabeled_preds_teacher = model.teacher_model(unlabeled_imgs)\n","            unlabeled_scores = list(unlabeled_preds_student.detach().cpu().numpy())\n","            unlabeled_true = list(np.around(unlabeled_preds_teacher.detach().cpu().numpy()))  ## make teacher outputs as binary label\n","            unlabeled_pred += unlabeled_scores\n","            unlabeled_lbl += unlabeled_true\n","            print(\"MAX: \", max(list(unlabeled_preds_teacher.detach().cpu().numpy())))\n","            print(\"MIN: \", min(list(unlabeled_preds_teacher.detach().cpu().numpy())))\n","\n","            # Consistency loss and total loss\n","            consistency_weights = model.get_consistency_weight(epoch)\n","            consistency_loss = consistency_weights * consistency_criterion(unlabeled_preds_student, unlabeled_preds_teacher) / batch_size   ## global var = 12\n","\n","            # Backward pass and optimization\n","            loss = supervised_loss + consistency_loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Update teacher model parameters\n","            model.update_teacher_model(cur_epoch=epoch, max_epoch=epochs)\n","            total_loss += loss.item()\n","\n","        # Unlabeled metrics\n","        unlabeled_lbl, unlabeled_pred = np.array(unlabeled_lbl), np.array(unlabeled_pred)\n","        unlabeled_pred_lbl = np.around(unlabeled_pred)\n","        unlabeled_train_auc = roc_auc_score(unlabeled_lbl, unlabeled_pred)  ## sometime pred will all false\n","        unlabeled_train_acc = accuracy_score(unlabeled_lbl, unlabeled_pred_lbl)\n","        unlabeled_acc_train_list.append(unlabeled_train_acc)\n","        unlabeled_auc_train_list.append(unlabeled_train_auc)\n","\n","        # Validation\n","        gpu_clean()\n","        val_lbl, val_pred = [], [] ## for AUC\n","        for (imgs, targets) in val_loader:\n","            imgs = imgs.to(device)\n","            targets = targets.to(device)\n","\n","            preds = model.student_model(imgs)\n","            targets = targets.unsqueeze(1)\n","            targets = targets.float()\n","\n","            val_scores = list(preds.detach().cpu().numpy())\n","            val_true = list(targets.detach().cpu().numpy())\n","            val_pred += val_scores\n","            val_lbl += val_true\n","        \n","        val_lbl, val_pred = np.array(val_lbl), np.array(val_pred)\n","        val_pred_lbl = np.around(val_pred)\n","        val_auc = roc_auc_score(val_lbl, val_pred)\n","        val_acc = accuracy_score(val_lbl, val_pred_lbl)\n","        acc_val_list.append(val_acc)\n","        auc_val_list.append(val_auc)\n","\n","        loss_train_list.append(total_loss)\n","        my_lr_scheduler.step()\n","        print(\"Epoch [{}/{}], Loss: {:.4f}, Unlabeled Train Acc: {:.4f}%, Unlabeled Train AUC: {:.4f}, Val Acc: {:.4f}%, Val AUC: {:.4f}\".format(\n","            epoch+1,epochs,\n","            total_loss/len(labeled_loader),\n","            unlabeled_acc_train_list[-1]*100,\n","            unlabeled_auc_train_list[-1],\n","            acc_val_list[-1]*100,\n","            auc_val_list[-1]\n","        ))\n","\n","\n","    return model, unlabeled_acc_train_list, unlabeled_auc_train_list, acc_val_list, auc_val_list\n","\n","\n","resnet50 = get_resnet50(pre_trained=True)\n","model = Model(resnet50, 1)\n","model = model.cuda()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","student_model = model\n","student_model.to(device)\n","\n","mean_teacher_model = MeanTeacherModel(student_model, ema_decay=0.99)\n","mean_teacher_model.to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","consistency_criterion = nn.MSELoss()\n","supervised_criterion = BCEFocalLoss()\n","my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)\n","\n","mean_teacher_model, UNLAB_ACC_TRAIN, UNLAB_AUC_TRAIN, ACC_VAL, AUC_VAL = train_mean_teacher(mean_teacher_model, train_loader, unlabeled_loader, val_loader, optimizer, consistency_criterion, supervised_criterion, device, epochs=2)"]},{"cell_type":"markdown","metadata":{"id":"5Q4AZq_enGEI"},"source":["### 5.2, Test model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vfSsJ4AbnEID","executionInfo":{"status":"aborted","timestamp":1683969340564,"user_tz":-480,"elapsed":3,"user":{"displayName":"BonKong Lai","userId":"14934257860777894140"}}},"outputs":[],"source":["# Evaluation\n","mean_teacher_model.eval()\n","test_lbl, test_pred = [], []\n","\n","for data in test_loader:\n","    test_images, test_labels = data\n","    test_images = test_images.to(device)\n","    test_labels = test_labels.float().to(device)\n","    test_outputs = mean_teacher_model.student_model(test_images)[:, 0]\n","    y_scores = list(test_outputs.detach().cpu().numpy())\n","    y_true = list(test_labels.detach().cpu().numpy())\n","    test_lbl += y_true\n","    test_pred += y_scores\n","        \n","test_lbl, test_pred = np.array(test_lbl), np.array(test_pred)\n","test_pred_lbl = np.around(test_pred) # pred >= 0.5 pred_lbl = 1 else pred_lbl = 0\n","test_auc = roc_auc_score(test_lbl, test_pred)\n","test_acc = accuracy_score(test_lbl, test_pred_lbl)\n","print(test_auc, test_acc)"]},{"cell_type":"markdown","metadata":{"id":"HlKYDx8JI4_M"},"source":["### 6, plot your training and test curves"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PB3pjrhWneY_"},"outputs":[],"source":["# Plot loss curve\n","fig = plt.figure()\n","plt.plot(loss_train_list, label='Training Loss')\n","plt.plot(loss_val_list, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Loss Curve')\n","plt.legend()\n","plt.show()\n","\n","# Plot accuracy curve\n","fig = plt.figure()\n","plt.plot(acc_train_list, label='Training Accuracy')\n","plt.plot(acc_val_list, label='Validation Accuracy')\n","plt.axhline(y=test_acc, color='r', linestyle='--', label='Test Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy Curve')\n","plt.legend()\n","plt.show()\n","\n","# Plot AUC curve\n","fig = plt.figure()\n","plt.plot(auc_train_list, label='Training AUC')\n","plt.plot(auc_val_list, label='Validation AUC')\n","plt.axhline(y=test_auc, color='r', linestyle='--', label='Test AUC')\n","plt.xlabel('Epoch')\n","plt.ylabel('AUC')\n","plt.title('AUC Curve')\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1DLtw9mX04n0VIn7RPIrnJafnEyfX_CoY","timestamp":1683711057979},{"file_id":"https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022-labs/blob/main/lab02/notebooks/lab02b_cnn.ipynb","timestamp":1676776020914}],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"0f056848cf5d2396a4970b625f23716aa539c2ff5334414c1b5d98d7daae66f6"}}},"nbformat":4,"nbformat_minor":0}